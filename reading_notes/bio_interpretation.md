* SHAP value
* weights Way and Green
* latent arithmetic Way + see the other ref
* network architecture
* enrichment

Shu et al. 2021 DeepSEM, a deep
generative model that can jointly embed the gene expression data and simultaneously construct a GRN that reflects the inner struc- ture of gene interactions in single cells without relying on any addi- tional information such as TF binding motifs or single-cell ATAC sequencing (scATAC-seq) data.

a beta-variational autoencoder (beta-VAE)23
in which
the weights of both the encoder and decoder functions represent the adjacency matrix of the GRN.



By inspecting the architecture of the model that represents the inner workings of a cell, we can observe how multiple genes interact with each other to determine the expression levels of individual genes

Another important functional component of DeepSEM is to
simulate scRNA-seq data by perturbing the values of its hidden neu- rons. In silico data simulations have already achieved tremendous success in computer vision for data augmentation, especially when the number of training samples is limited24
. In single-cell biology,
the same types of simulation algorithm have also been applied to scRNA-seq data to predict the single-cell perturbation response out of sample19,25
, identify marker genes26
and augment the sparse cell
populations to improve the accuracy of cell-type classification27



Different from conventional deep learning models that embed the expressions of all the genes together into a latent space6,7
,
the encoder function of DeepSEM takes the expression of only one gene as the input feature of the neural network. The neural net- works for different genes share their weights or it could be viewed as using one neural network to scan all the genes. At this step, there are no interactions among different genes in the model. Later, another two fully connected neural networks transform the output of these small neural networks to the posterior mean and standard devia- tion of a multivariate Gaussian distribution. Decoupling the non- linear operation and the gene interaction is the key for DeepSEM to achieve more robust and interpretable hidden representations at the same time.



Structural equation modeling is a multivariate statistical model to analyze structural relationships among different random variables



the SEM can be adopted to detect the conditional dependency among random variables and therefore also used to predict the graph structure of Bayesian networks and Markov random fields53–56
. DeepSEM generalizes the SEM, which
models the conditional dependencies among random variables and is formulated as a self-regression problem





Cao and Gao 2021

Taking advantage of prior biological knowledge, we propose the use of a knowledge-based graph 2 (“guidance graph”) that explicitly models cross-layer regulatory interactions for linking layer- 3 specific feature spaces; the vertices in the graph correspond to the features of different omics layers, 4 and edges represent signed regulatory interactions.

Combining omics-specific autoencoders with graph-based coupling and adversarial alignment, we 24 designed and implemented the GLUE framework for unpaired single-cell multi-omics data 25 integration with superior accuracy and robustness. By modeling regulatory interactions across omics 26 layers explicitly, GLUE uniquely supports model-based regulatory inference for unpaired multi- 27 omics datasets, exhibiting even higher reliability than regular correlation analysis on paired datasets

Since different autoencoders are independently parameterized and trained on separate data, the cell 27 embeddings learned for different omics layers could have inconsistent semantic meanings unless 28 they are linked properly. To link the autoencoders, we propose a guidance graph ?? = (??, ℰ), which incorporates prior 2 knowledge about the regulatory interactions among features at distinct omics layers,

We treat the guidance graph as observed variable and model it as generated by low-dimensional 14 feature latent variables (i.e., feature embeddings) ??(



Gut et al. 2021

To improve interpretability, methods have incorporated biological priors, like pathway defi- nitions, directly into the learning task. However, due to the correlated and redundant structure of pathways, it is difficult to determine an appropri- ate computational representation

t pathway module Variational Autoencoder (pmVAE). Our method utilizes pathway information by restricting the structure of our VAE to mirror gene-pathway memberships.

Its architecture is composed of a set of subnet- works, refered to as pathway modules, that learn interpretable multi-dimensional latent representa- tions by factorizing the latent space according to pathway gene sets. We directly address correla- tions between pathways by balancing a module- specific local loss and a global reconstruction loss

A natural way to identify which pathways are altered in a dataset is to correlate the learned parameters against external pathway or clinical data to explain the latent components. While this approach has proven fruitful (Dincer et al., 2018; Kompa & Coker, 2020; Tan et al., 2014; Way & Greene, 2018; Way et al., 2020), it requires careful analysis to iden- tify what each component is capturing, especially since all features are likely not fully disentangled (Locatello et al., 2019).

shortcomings with pathways:

- they are highly correlated and overlapping
- Many higher-level pathways (e.g., the immune system) will contain possibly disparate signals from more specific and independent pathways (e.g., T-cell and B-cell signaling) and require a richer representation.

constructs a pathway factorized latent space that directly addresses the problem of overlapping pathway definition

The pathway modules within pmVAE construct a latent space factorized by pathways. 

Given a set of K pathways, each represented as a set of genes, pmVAE consists of K pathway modules, which each behave as a VAE constrained to the set of genes that participate in its pathway. The outputs of these modules are then combined to reconstruct the expression vector of a single cell.



. pmVAE is a variational autoencoder for expression data that constructs an interpretable latent space factorized by pathway gene sets. These pathway modules encode and decode the genes contained in their gene sets, forming a latent space for each path- way. A global reconstruction is achieved by summing over all pathway module outputs and a custom training procedure is imple- mented to address optimization challenges caused by overlapping pathways.

pmVAE attempts to explain the data with the most concise set of relevant modules to explain the data. 

pmVAE’s ability to remove redundant pathway signals,

pmVAE does not find the upstream pathway scores as discriminative because the directly targeted pathways al- ready explain the variability across the cells.

pmVAE identifies non- redundant pathway representations by explaining the pertur- bation effect with only the most specific pathways.

pmVAE also finds three additional pathways to be discrimi- native of the cell’s perturbation state that is neither up- nor downstream of the targeted pathways. We believe that these biological processes are also discriminative because cell- type and perturbation status are entangled signals within our dataset.

In contrast to interpretable AE and f-scLVM, pmVAE provides a per-pathway multidi- mensional representation. This representation enables us to interrogate pathway-specific biological features, such as cell-type-specific effects

By incorporating pathway membership into the architectural design, pmVAE constructs a latent space fac- torized by pathway. This design enables direct association between the resulting pathway scores and clinically relevant features.



Oh et al. 2021

PathCNN, that constructs an interpretable CNN model on integrated multi-omics data using a newly defined pathwayimage.



To increase the in- terpretability of classical CNNs in image problems, an approach called Class Activation Mapping (CAM) was developed using global average pooling (Zhou et al., 2016). CAM produces a localization map for a target class, visualizing the discriminative image regions used by the CNN to predict the class.

CAM has some lim- itations: (i) to employ CAM, the CNN architecture used in modeling should be modified by removing fully connected layers and adding a global average pooling layer after the last convolutional layer where class activation maps are generated, and (ii) the modified network for CAM should be fine-tuned. A

A more generalizable approach, called Gradient-weighted Class Activation Mapping (Grad-CAM), was subsequently proposed, which uses the gradient information of any target class flowing into the last convolutional layer to produce class activation maps (Selvaraju et al., 2017). 

we propose a novel method, called PathCNN,to
build an interpretable CNN model of cancer outcomes using multi- omics data. As input data to the CNN model, pseudo images of biological pathways (called pathway images) are used, which are generated in the low dimensional space of integrated multi-omics data including mRNA expression, copy number variation (CNV) and DNA methylation. After modeling, to identify the biological pathways associated with outcomes, Grad-CAM is used, for which attention maps superimposed on pathway images are analyzed to pinpoint key pathways.

the resulting CNN model achieves much better pre- dictive performance compared to other methods. Furthermore, the model employing Grad-CAM is interpretable, enabling the visual identification of influential biological pathways

Each type of omics data at a gene level was converted into pathway level profiles. To do this, pathway information was first extracted, along with the associated genes for each pathway from the Kyoto Encyclopedia of Genes and Genomes (KEGG) database (Kanehisa

s, the matrix B consists of samples in rows and genes for a given pathway in col- umns.. Using principal component analysis (PCA), the matrix B was decomposed into uncorrelated components, 

This task for the pathway pi was also carried out on the CNV matrix (C) and DNA methylation matrix (M),

The process was repeated for all 146 pathways, resulting in the merged matrices

A combined matrix of the three matrices is called the pathway image of the
sample sj, where rows represent 146 pathways, and columns repre- sent 3?q PCs combined for the three omics types, which was input into a CNN model.

, a few PCs (q=1–5) were used; for example, a sample (pathway image) is represented by a matrix with 146x6 elements for q=2, where the first and second columns are from mRNA expression, the third and fourth columns are from CNV, and the fifth and sixth columns are from DNA methylation, representing the first two PCs of each omics type.

To identify the important pathways associated with LTS in GBM, Grad-CAM was used, which is a technique to localize discriminative image regions.

Thus, if correlated pathways are clustered on path- way images, Grad-CAM is more likely to identify key pathways. This is also consistent with the nature of CNNs that capture local patterns in input images through various filters. It

It is intuitively rea- sonable to place correlated pathways in proximity on the pathway images to better localize important regions. Hence, the 146 path- ways were ordered in the following manner: Pearson correlation be- tween pathways was computed on a matrix of 146 by (number of samples ? number of PCs ? 3), generated by combining all resultant pathway images. The two most correlated pathways were placed on the top two rows on the pathway images, and then a pathway that was the most correlated with the pathway in the second row was placed on the third row. This process was repeated for all 146 path- ways. Note that the ith pathway was located among those not previ- ously selected, and it was the most correlated with the pathway in the row i?1. As a result, all pathway images had the same order of pathways.

Grad-CAM for class-discriminative localization mapping was employed to identify the important pixels (pathways) on pathway images associated with LTS in GBM patients (Fig. 3A)(Selvaraju et al., 2017). Class activation maps were generated by computing the gradient of a score (yc) for each class c with respect to feature maps A of the last convolutional layer. More specifically, neuron importance weights wc for a class c were computed

Unlike the modeling with cross validation, for biological inter-
pretation using Grad-CAM, a CNN model was built using all sam- ples. Each sample was fed into the model, leading to two activation maps (for LTS and non-LTS). A difference map between the two ac- tivation maps was thereby produced. After repeating this process for all samples, a statistical analysis was conducted.



Ma and Zhang 2019

e Factor Graph Neural Network model that is interpretable and predictable by combining probabilistic graphical models with deep learning. We directly encode biological knowledge such as Gene Ontology as a factor graph into the model architecture, making the model transparent and interpretable. Furthermore, we devised an attention mechanism that can capture multi-scale hierarchical interac- tions among biological entities such as genes and Gene Ontology terms.

We applied our model to two cancer genomic datasets to predict target clinical variables 

 Our model can also be used for gene set enrichment analysis and selecting Gene Ontology terms that are important to target clinical variables

the Factor Graph Neural Network (FGNN) model, which directly encodes biological knowledge such as Gene Ontology into the model architecture

Unlike the hidden nodes in conventional deep learning models which do not have a physical meaning, each node (i.e., “neuron”) in the Factor Graph Neural Network model corresponds to some biological entity (such as genes or Gene Ontology terms), making the model transparent and interpretable. We

We not only address the model interpretability challenge but also make the model generalize well by directly incorporating biological knowledge as inductive biases Battaglia et al. (2018) into the model architecture.

We also devised a parameter sharing mechanism to significantly reduce the number of model parameters and yet maintain the high representation power of deep learning models. 

Furthermore, we applied the attention mechanism to capture hierarchical multi-scale interactions between Gene Ontology terms and genes.

Our model can be used for gene set enrichment analysis as well. E

our proposed Factor Graph Neural Network model uses graphs from domain knowledge as model architecture and predicts clinical target variables.

Our proposed Factor Graph Neural Network model is highly expressive and interpretable by combining the strength of interpretability of factor graphs in probabilistic graphical models and the supreme representation power of deep neural network

With parameter sharing mechanism, our proposed Factor Graph Neural Network model can also be trained with stochastic depth, which can further boost the model generalizability

One key to the success of CNN and other deep learning models is the use of proper relational inductive biases (Battaglia et al., 2018). For CNN, the inductive biases include the locality (parameter sharing) and the translational invariance

To build predictable and generalizable deep learning models in the biomedical domain, we can incorporate some prior knowledge as inductive bias into the model, too. In this paper, our Factor Graph Neural Network model encodes the factor graph from domain knowledge as an inductive bias into the model architecture. It generalizes the Graph Convolutional Network (GCN) (Kipf &Welling, 2016) and can capture hierarchical multi-scale interactions with attention mechanisms.

In many applications, there are two types of variables: observable variables and latent variables. Latent variables can be seen as “factors” that are related to observable variables. For example, gene expressions are measured in many genetic disease studies. These gene expressions are observable variables. A pathway or Gene Ontology (GO) term involves multiple genes and gene products, but their activities are not directly observable. These pathways and GO terms constitute various factors in a gene network. Since these hidden factors are not directly observable, many models directly use observable variables for predicting target variables such as clinical outcomes.

to make our Factor Graph Neural Network model predictable and generalizable, we incor- porate prior knowledge such as Gene Ontology annotations as the inductive bias into the model architecture.

Genes and Gene Ontology (GO) terms form a bipartite graph. There are two types of nodes (i.e., gene nodes and GO nodes). Each GO term is associated with a number of genes and gene products. GO terms are treated as factors in the Factor Graph Neural Network model. (Note we can also use pathways or other gene sets derived from biological knowledgebase as factors.) Based on Gene Ontology annotations, we can build a factor graph with GO terms as factors and genes as observable variables. This factor graph encodes domain knowledge and can be used as an inductive bias for constructing the Factor Graph Neural Network model.



The nodes in the input layer are genes, and the nodes in the hidden layer are GO terms. The output layer is the target clinical outcomes.

There is an edge between a gene and a GO term if and only if the gene is included in the GO term. Therefore the network is not fully connected between the input layer and the hidden layer. Instead, the connections are determined by the relationships between GO terms (factors) and genes (observable variables).

The two-layer Factor Graph Neural Network model as shown in Fig. 2 is a two-layer neural network with its hidden layer corresponding to Gene Ontology terms and the edges determined by the Gene Ontology annotations. It is usually not sufficient for modeling complex nonlinear transformations with a “shallow” architecture. In order to make this model more expressive to model complex nonlinear transformations, we can unroll this Factor Graph Neural Network model to make it have more layers as deep neural networks can have more expressive power

The input layer is the observable gene expressions x. The first hidden layer corresponds to the GO terms. The second hidden layer corresponds to some latent state of genes. The rest of the hidden layers all correspond to latent states of genes or GO terms. The output layer is the target clinical variable y

By unrolling the factor graph neural network model, we introduced multiple composable nonlinear transformations, making the model able to approximate any complex nonlinear functions

, there can be infinitely many layers by unrolling the model

In order to reduce the risk of overfitting, we adopt a parameter sharing mechanism similar to recurrent neural networks and the Transformer model (Vaswani et al., 2017). Different from convolutional neural networks where parameter sharing is within a single layer, our factor graph neural network model shares parameters across layers

There are two set of parameters in this unrolled factor graph neural network model: one used to map genes to GO terms, and the other map GO terms to genes. We

In an unrolled factor graph neural network model with multiple layers, we can share these two set of parameters (corresponding to the two set of transformations from variables to factors and vice versa) across layers. As the same set of parameters are used between variables and factors in all the layers, we can significantly reduce the number of model parameters. Since there can be multiple layers corresponding to genes and GO terms, we can add skip connections as in ResNet (He et al., 2016) to connect the previous gene/GO layers to the current gene/GO layers. This can help gradient flow and speed up training.

Up to now we only considered immediate interactions among nodes in a factor graph, i.e., the direct connection between observable variables and factors. With unrolled factor graph neural network, we can naturally incorporate multi-scale hierarchical interactions into the model using attention mechanisms.

To enable multi-scale hierarchical interaction in an unrolled factor graph neural network model, we connect the lth layer with all previous (l − 1) layers

There will be an edge between a node in the lth layer and a node in the (l − 1)th layer if and only if node i can reach node j in the factor graph in one step. In other words, j is the direct neighbor of i. Similarly, there will be an edge between node i in the lth layer and node j in the
(l − k)th layer if and only if node i can reach node j in k steps. For

This idea is very much like convolutional neural networks (CNN) on graphs, where the neurons in the high-level layers will have a larger reception field. The difference is that in a CNN model, the number of neurons in each layer will be decreased by a factor of the stride, and the new feature plane no longer has a clear interpretable physical meaning. By contrast, every neuron in the factor graph neural network model corresponds to some physical entity (genes or GO terms), making the model transparent and interpretable. 

the attention matrices that are used to connect all the layers in a factor graph neural network model to capture multi-scale hierarchical interactions.
we apply the attention mechanism to assign weights to connections between different layers. 

The unrolled factor graph neural network model is based on the factor graph which encodes biological knowledge such as Gene Ontology annotations. (Note a factor graph is a data structure encoding biomedical domain knowledge, while the factor graph neural network model is a deep neural network model which uses the domain knowledge factor graph as the model backbone.

A factor graph can be seen as an undirected bipartite graph. There are two node sets: source variables and target factors. Based on the network topology, we can calculate the state transition matrices from source to target and vice versa.

calculate the attention matrices from the state transition matrices.

These attention matrices provide with the weights for the connections across different layers, which capture multi-scale hierarchical interactions among nodes.

If we have additional topological information about the factors such as Gene Ontology hierarchical structure, we can also encode the network hierarchy in the Factor Graph Neural Network model. A

This hierarchical network can be seen as a directed acyclic graph. Each node can be seen as a factor with its domain being all its children. Thus the factor graph neural network can be applied to encode network hierarchy as well.

The factor graph neural network model can also be used for gene set enrichment analysis (GSEA). Currently,

The factor graph neural network can be used to identify gene sets that are relevant to target clinical variables of interest based on stochastic gradient descent.

each GO term is associated with a set of genes and can thus be seen as a gene set. Our approach can be applied to identify enriched gene sets by training the model end-to-end. The weights of the last layer from the gene sets to the target clinical variable can be used to select gene sets that are most relevant to the target variable.



Elmarakeby et al. 2021

 P-NET—a biologically informed deep learning model—
to stratify patients with prostate cancer by treatment-resistance state and evaluate molecular drivers of treatment resistance for therapeutic targeting through complete model interpretability.



P-NET can predict cancer state using molecular data with a performance that is superior to other modelling approaches



, the biological interpretability within P-NET revealed established and novel molecularly altered candidates, such as MDM4 and FGFR1, which were implicated in predicting advanced disease and validated in vitro.

biologically informed fully interpretable neural networks enable preclinical discovery and clinical prediction in prostate cancer and may have general applicability across cancer types.

development of multiple attribution methods, including LIME20
, Deep- LIFT13
, DeepExplain21
and SHAP22 , that can be used to enhance the deep
learning explainability and understand how the model is processing information and making decisions.

customized neural network architectures that are inspired by biological systems. For example, vis- ible neural networks were developed to model the effect of gene inter- action on cell growth in yeast (DCell) and cancer cell line interactions with therapies (DrugCell)3,5
. A pathway-associated sparse deep neural
network (PASNet) used a flattened version of pathways to predict patient prognosis in Glioblastoma multiforme2

P-NET is a neural network architecture that encodes different biological entities into a neural network language with customized connections between consecutive layers (that is, features from patient profile, genes, pathways, biological processes and outcome). In this study, we focus primarily on processing mutations and copy-number alterations. The trained P-NET provides a relative ranking of nodes in each layer to inform generation of biological hypotheses.

A set of 3,007 curated biological pathways were used to build a pathway-aware multi-layered hierarchical network (P-NET) (

, the molecular profile of the individual is fed into the model and distributed over a layer of nodes representing a set of genes using weighted links

. Later layers of the network encode a set of pathways with increasing levels of abstraction, whereby lower layers represent fine pathways and later layers represent more complex biological pathways and biological processes.

The connections between different layers are constrained to follow known child–parent relationships among encoded features, genes and pathways, and as a result the network is geared toward **interpretability by design**

To evaluate the relative importance of specific genes contributing to
the model prediction, we inspected the genes layer and used the Deep- LIFT attribution method to obtain the total importance score of genes

. To understand the behaviour of trained P-NET, we checked the activation of each node in the network, where activation here represents the signed outcome of a certain node given its inputs, and tested whether this activation changed with the change of the input sample class (primary versus metastatic) (Methods).

We observed that the difference in the node activation was higher in higher layers and more concentrated in highly ranked nodes in each layer (Extended Data Fig. 8). For example, the activation distribution of the nodes of layer H3 was different when P-NET was given a primary sample compared with a resistant sample (Extended Data Fig. 8c). Thus, the interpretable architecture of P-NET can be interrogated to understand how the input information is trans- formed through layers and nodes, enabling further understanding of the state and importance of the involved biological entities.

(see fig. 3 nice vizualization with flow chart Sankey diagram)

Through evaluation of multiple layers in the P-NET trained model,
we observed convergence in TP53-associated biology contributing to CRPC. Tracing the relevance of TP53-related pathways to the gene levels, roles for TP53 and MDM2 have been previously established in prostate cancer disease progression32,34–40
, we also observed alterations
in MDM4 that contributed substantially to this network convergence.

Visualization of inner layers of P-NET shows the estimated relative importance of different nodes in each layer.

The contribution of a certain data type to the importance of each gene is depicted using the Sankey diagram—for example, the importance of the AR gene is driven mainly by gene amplification, the importance of TP53 is driven by mutation, and the importance of PTEN is driven by deletion.

P-NET provided a simple way for integrating multiple molecular features (for example, mutations, copy number variations and fusions, among others) weighted differently to reflect their impor- tance in predicting the final outcome, which previously required dif- ferent statistical approaches for each feature to enable cancer gene discovery44,45
., P-NET provided a framework for encoding
hierarchical prior knowledge using neural network languages and turn- ing these hierarchies into a computational model that can be used both for prediction and for biological discovery in clinicogenomic contexts

. Visualization of the architecture of P-NET enabled a multilevel view of the involved biological pathways and pro- cesses, which may guide researchers to develop hypotheses regarding the underlying biological processes involved in cancer progression and translate these discoveries into therapeutic opportunities.

In addition, P-NET encodes biological pathways inside the network in a hardcoded way, which makes the model dependent on the quality of the annotations used to build the model. Use of models that leverage other hardcoded biological priors (such as KEGG and Gene Ontology) or user-specified specific biological modules may further guide model development and functional evaluation

P-NET is a feedforward neural network with constraints on the nodes and edges. In P-NET, each node encodes some biological entity (for example, genes and pathways) and each edge represents a known relationship between the corresponding entities. The constraints on the nodes allow for better understanding of the state of different bio- logical components. The constraints on the edges allow us to use a large number of nodes without increasing the number of edges, which leads to a smaller number of parameters compared to fully connected networks with the same number of nodes, and thus potentially fewer computations. 

The architecture was built using the Reactome pathway datasets46

The whole Reactome dataset was downloaded and processed
to form a layered network of five layers of pathways, one layer of genes, and one layer for features.

the P-NET model is not bound to a certain architecture, as the model architecture is automatically built by reading model specifications provided by the user via a gene matrix transposed file format (.gmt) file, and custom pathways, gene sets and modules with custom hierarchies can be provided by the user

The input layer is meant to represent features that can be measured and fed into the network. The second layer represents a set of genes of interest. The higher layers represent a hierarchy of pathways and biological processes that are manually curated. The first layer of P-NET is con- nected to the next layer via a set of one-to-one connections, and each node in the next layer is connected to exactly three nodes of the input layer representing mutations, copy number amplification and copy number deletions. 

. The second layer is restricted to have connections reflecting the gene-pathway relationships as curated by the Reactome pathway dataset. The connections are encoded by a mask matrix M that is multiplied by the weights matrix W to zero-out all the con- nections that do not exist in the Reactome pathway dataset. 

For the next layers, a similar scheme is devised to control the connection between consecutive layers to reflect the real parent–child relation- ships that exist in the Reactome dataset. 

. We checked different gradient-based attribution meth- ods to rank the features in all the layers, and we chose to use the Deep- LIFT scheme as implemented in the DeepExplain library13
.

DeepLIFT is a backpropagation-based attribution approach for
assigning a sample-level importance score for each feature. In this work, we are interested in assigning scores for each node in each layer. Given a certain sample, a specific target t, and a set of layer nodes [...], DeepLIFT calculates an importance score Ci
ls, for each node on the
basis of the difference in the target activation t – t0
such that the dif-
ference equals the aggregation of the calculated scores for all the nodes.

this is an absolute score (always positive) that measures the impact of a certain node on the outcome. The activation of the cor- responding node i, however, could be positive or negative.

To reduce the bias introduced by over-annotation of certain nodes
(nodes that are member of too many pathways), we adjusted the Deep- LIFT scores using a graph informed function f that considers the con- nectivity of each node.

The implementation of the proposed system along with the reproducible results are available on GitHub (https://github.com/marakeby/pnet_prostate_paper)



Kuenzi et al. 2020

DrugCell, an interpretable deep learning model that simulates the response of human cancer cells to therapy. 

DrugCell predictions might generalize to patient tumors and can be used to design synergistic drug combinations that significantly improve treatment outcomes.

Model interpretations represent synergistic drug combination opportunities

Response predictions stratify ER-positive breast cancer patient clinical outcomes

DrugCell, an interpretable deep learning model of human cancer cells trained on the responses of 1,235 tumor cell lines to 684 drugs. . Tumor genotypes induce states in cellular subsystems that are integrated with drug structure to predict response to therapy and, simultaneously, learn biological mechanisms underlying the drug response. DrugCell predictions are accu- rate in cell lines and also stratify clinical outcomes. Analysis

Analysis of DrugCell mechanisms leads directly to the design of synergistic drug combinations, which we validate systematically by combinatorial CRISPR, drug-drug screening in vitro, and patient-derived xenografts.

In a typical application (reviewed in Table S1), the model uses the ’omics profile of a cell line or tissue sample as input to predict the 50% inhibitory concentration (IC50) of a drug.

model interpretation; One major strategy has been to use prior knowledge or data to add structure to the model, which can then be interpreted. Applied to genomics, such a strategyhasbeenused to recast the thousands of measuredmo- lecular features of a tumor as states on a much smaller number of functional modules (Corte´s-Ciriano et al., 2016; Yang et al., 2019).

One major strategy has been to use prior knowledge or data to add structure to the model, which can then be interpreted. Applied to genomics, such a strategyhasbeenused to recast the thousands of measuredmo- lecular features of a tumor as states on a much smaller number of functional modules

For example, a recent studymappedrawmolecularmeasurements toasetof pre-definedmetabolicpathwaysdrawn fromprior knowl- edge bases; the states of these pathways predict antibiotic resis- tance inEscherichiacoli,withparticularpathwayfeaturesemerging ascandidatemechanisms of resistance (Yang et al., 2019).

Organi- zation of molecular features into predictive modules can also be accomplished using prior data as opposed to literature-curated knowledge. Such an approach was recently exemplified by Deep- Profile, which analyzed a large collection of leukemia expression profiles to extract a low-dimensional representation of these data as a set of functional gene modules; these modules are then used as interpretable features for drug response prediction (Dincer et al., 2018). 

Apart frommodel-basedapproaches, a secondmajor strategy to increasemodel interpretabilityhasbeen toperformpost hoc analysis of model features or feature weights to interpret the underlying drug response mechanisms

, the weights as- signed to each input gene by a black-box neural network model are subjected to gene set enrichment analysis (Subramanian et al., 2005) to identify pathways regulating the predicted drug response (Sakellaropouloset al., 2019). Thesepathways, however, were not used during modeling or validated experimentally. To

To more explicitly link the structure of a machine learning
model to cellular functions, we recently developed a visible neu- ral network (VNN) simulating a simple eukaryotic cell, Saccharo- myces cerevisiae (Ma et al., 2018; Yu et al., 2018). This model,
called DCell, was made mechanistically interpretable, or ‘‘visible,’’ by directly mapping the neurons of a deep neural network into a large hierarchy of known and putative molecular components and pathways.

DrugCell, a VNN that simulates the response of human cancer cells to therapeutic chemical compounds. DrugCell couples the inner workings of the model to the hierar- chical structure of human cell biology, allowing for response pre- dictions for any drug in any cancer and intelligent design of effec- tive combination therapies.

d DrugCell as a neural network with two branches

The first branch was a VNN modeling the hierarchical organization of molecular subsystems in a hu- man cell, drawn from 2,086 biological processes documented in the Gene Ontology (GO) database

Each of these subsystems, from those involving small protein complexes (e.g., b-catenin destruction complex) to larger signaling pathways (e.g., MAPK signaling pathway) to overarching cellular functions (e.g., glycolysis), was assigned a bank of artificial neurons to represent the state of that subsystem

Connectivity of neurons was set to mirror the biolog- ical hierarchy, so that neurons accept inputs only from child sub- systems and send outputs only to parent systems, with connec- tion weights determined during training. The use of multiple neurons per subsystem (here six, see STAR Methods) allowed cellular subsystems to be multifunctional, with distinct states able to adopt a range of values along multiple dimensions

The input layer of the hierarchy mapped to the mutation status of genes. The six neurons at the VNN output, corresponding to the root of the hierarchy, represented the embedded state of the whole cell based on its genotype

The second branch of DrugCell was a conventional artificial neu- ral network (ANN) embedding the Morgan fingerprint of a drug, a canonical vector representation of chemical structure

Outputs from the two branches of the model, the VNN embedding cell genotype and the ANN embedding drug structure, were combined in a single layer of neurons, which were then integrated to generate the response of a given genotype to a particular treatment

(https://github.com/ idekerlab/DrugCell)

we next turned to mecha- nistic interpretation. This task was aided by the two model branches, which dissect the effects of genotype on the configu- ration of cell systems (genotype embedding) from the effects of chemical structure on drug activity within the cell (drug embed- ding,

We visually inspected these embeddings by plotting the top two principal components

Since DrugCell’s VNN is structured according to the hierarchy
of biological subsystems comprising a human cell, its output (ge- notype embedding) is the result of state changes in particular subsystems within that hierarchy

To identify the most important of these subsystems, we scored subsystems by the degree to which their states were significantly more predictive of a drug response than the states of their child subsystems using the rela- tive local improvement in predictive power metric (RLIPP

The parallel pathway inhibition theory of drug synergy (Yeh et al., 2009) holds that two drugs will be synergistic if they inhibit sepa- rate pathways that regulate a common essential function

The branched architecture of the DrugCell model (Figure 1A) mirrors this parallel pathway structure, in that the bio- logical activity of a drug is learned by the drug embedding branch, and the parallel pathways are learned by the genotype embedding branch (Figure 5B). 

Subsystems important for pre- dicting a drug response may therefore represent synergistic drug combination opportunities.

we used RLIPP scores to rank subsystems regulating sensitivity to 25 drugs in the §

we wished to evaluate how well DrugCell is able to suggest effective drug combinations. We used RLIPP scoring to rank subsystems by importance in mediating drug re- sponses to six primary drugs, filtering this list to those that con- tained secondary drug targets.

DrugCell has utility in guiding design of combination therapies in patient tumors

to evaluate whether DrugCell could be used clinically to stratify cancer patients into responsive and non- responsive patient populations

the mechanisms underlying the differ-
ential sensitivity between DrugCell (+) and DrugCell (?) patients by performing an RLIPP analysis for

DrugCell can be used to effectively guide clinical treatment decisions with significantly greater precision and insight than single-gene marker studies.

drug combinations can be selected automatically based on the druggable targets pre- sent in top DrugCell subsystems.

if DrugCell is be- ing used in a clinical context, its recommendations can be pro- vided to physician-scientists (e.g., a molecular tumor board) who consider the recommended combinations in light of other biological knowledge not explicitly used in modeling

The DrugCell VNN (the genotype embedding branch; Figures 1A and 1B) was configured following the DCell protocol (Ma et al., 2018)

Each subsystem s in DCell, and also in the hierarchy of subsystems in DrugCell (see above), is assigned a number k of neurons to represent its multidimensional state. This subsystem state, denoted by the output vector OðsÞ is defined as a function of the states of its c child subsystems and g directly annotated genes, concatenated in the input vector IðsÞ:

, in parallel to the subsystem hierarchy used to embed genotype, DrugCell implements a drug embedding branch configured as a conventional artificial neural network with three hidden layers, with the neurons of each layer fully connected to the next (these three layers have 100, 50, and 6 neurons respectively,

The input vector to this ANN is the 2,048-bit Morgan fingerprint of a drug (described above) and is fully-connected to the first hidden layer with 100 neurons. The

The final layer is a set of six neurons rep- resenting the drug embedding learned by DrugCell.

These six neurons are concatenated with the six-neuron genotype embedding and fed to an additional hidden layer of six neurons, which feeds a final output layer of a single neuron representing the predicted drug response, OðDCÞ, measured as a continuous valued AUC

). Second, the number of neurons per subsystem k (VNN branch, see above) is selected by training and evaluation of a progression of neural network models with increasing values of this parameter

The DrugCell model used for all subsequent analysis is configured with k = 6, as this value yielded the best Spearman rho between actual and predicted drug responses across all (cell-line, drug) pairs. T

To quantitatively determine important subsystems for drug response prediction, we adopted the Relative Local Improvement in Pre- dictive Power (RLIPP) score as described previously for DCell (Ma et al., 2018). Briefly, for each subsystem in DrugCell we constructed and compared two different L2-norm penalized linear regression models of drug response local to that subsystem. The first regression model predicts drug response using the neuron values that represent the state of the subsystem under the different genotypes. The second regression model predicts drug response using the neuron values that represent the states of the subsystem’s children. Both models are optimized to predict drug response, but with consecutive layers of neurons located at and below the subsystem of interest in DrugCell. Performance is calculated as the Spearman correlation (rho) between the actual and predicted drug responses for each of the two alternative linear regression models (AUC). TheRLIPPscore is then definedas the ratio ofSpearman rho of the first linear model to that of the second linear model. RLIPP > 1 reflects that the state of the parent subsystem has more predictive power for drug response than the mere concatenation of the states of its children, indicating the importance of the parent subsystem in learning.



Dincer et al. 2018 - NOT BIO INFORMED

DeepProfile framework, which learns a variational autoencoder (VAE) network from thousands of publicly available gene expres- sion samples and uses this network to encode a low-dimensional representation (LDR) to predict complex disease phenotypes.

use deep learn- ing to extract a feature representation from a vast quantity of unlabeled (i.e, lacking phenotype in- formation) expression samples that are not incor- porated into the prediction problem

We use Deep- Profile to predict acute myeloid leukemia patients’ in vitro responses to 160 chemotherapy drugs.

, most expression datasets are high-dimensional (i.e., #samples ? #variables) and therefore, it is challenging to use them to learn accurate prediction models. Learning a function that maps observed molecular features to an informative low- dimensional representation (LDR) is the key to success in overcoming the bane of dimensionality.

DeepProfile, which uses VAEs to learn an un- supervised neural network model of gene expression from thousands of cancer patients, and then uses this model to encode an LDR to predict complex phenotypes of patients excluded from network training

DeepProfile has three unique aspects. First, since DeepProfile learns an unsuper- vised model in the training step, it can use a vast quantity of samples from which only gene expression data is available. Second, it can encode an LDR for a new cancer patient by transferring network information learned by the trained model from a much greater number of individuals. Finally, this newly encoded LDR can be effectively used to predict any phenotype information for the new patient

the LDR learned based on DeepProfile can reconstruct input expression data and capture known gene pathways more accurately than LDRs based on PCA or k-means. Consistent

DeepProfile is different from all these approaches because it is the first to predict complex cancer phenotypes using an LDR learned based on a VAE trained from almost all of the available GEO patient expression samples for a cancer

DeepProfile transfers information from many patients with the same cancer type using a deep autoencoder to predict drug response. Also, DeepProfile uses only a small subset of genes while past studies show performance on the entire set of genes.

, DeepProfile: (1) learns a network repre- sentation from the gene expression of thousands ofAML pa- tients in an unsupervised way, (2) uses the learned network to encode an LDR for 30 held-out AML patient samples whose in vitro responses to 160 drugs are available, and (3) predicts the drug response of these patients using the en- coded LDR.

. Our VAE model consists of encoder and decoder networks, each with three dense layers

r (MSE) between input and reconstructed data and Kullback-Leibler (KL) divergence between the posterior and prior as an objective function and trained using Adam method

The DeepProfile framework. We combined standardized expression data collected from 96 studies and corrected batch effects both within each study and across studies. The genes with a median absolute deviation (MAD) higher than the mean MAD are selected and clustered. The VAE network is trained using a total of 300 gene clusters of 6,534 samples. Using the trained network, an 8-dimensional LDR is learned for each of the 30 AML patient samples, for which we have the in vitro response to 160 drugs. We use the LDR as an input of an L1-regularized linear regression to predict the response to each drug

corrected for the potential batch effects within each study using ComBat

standard- ized (i.e., made zero-mean and unit variance) each gene in each dataset to ensure that different input features (here, gene expression levels) were on the same scale.

applied batch effect correction to the entire data set once again using ComBat, considering each study to be a separate batch

removed the genes that had a median absolute deviation (MAD) below the mean MAD.

h we divided into 300 clusters (using agglomerative clustering) so that those with similar expression patterns were grouped to- gether, reducing the noise and dimensionality of the feature space. We

centroids of the learned 300 clusters to train the VAE model.

 Then we used the network learned by VAE to encode an 8-dimensional LDR for each of the 30 AML pa- tient samples measured in terms of genome-wide gene expression and in vitro response to 160 chemotherapy drugs.

We used the encoded LDR in an L1-regularized linear regression setting and measured drug response prediction performance for these patients separately for each drug. We

The goal of this experiment is to determine whether the transferred network learned in an unsupervised manner from large amounts of data from a cancer type would help with the task of phenotype prediction for new patients with the same type of cancer. For k-means clustering, we learned 8 gene clusters and used the cluster centroids as LDR, while for PCA, we used top 8 principal components

we checked whether the genes that belong to known functional pathways (1,077 Reactome, BioCarta, and KEGG GeneSets from the C2 collection of the cur- rent version of MSigDB (Subramanian et al., 2005) are highly ranked by DeepProfile. We

We computed the weights of each gene for each of the 8 LDR features (i.e., how much each gene contributed to the value of each LDR feature) learned based on PCA, k-means, or DeepPro- file. We

We determined gene weights using the Keras imple- mentation of the Integrated Gradients method (Sundarara- jan et al., 2017) provided at https://github.com/ hiranumn/IntegratedGradients. We

For each pathway, we performed the permutation test for the top LDR feature from each method (i.e., the embedding with the highest average ranking of the pathway genes) because it is common that in a DNN model like VAE, each hidden node captures a separate functional unit that contributes to the learned meaningful representa- tion of the data. Thus, we believe that it is reasonable to assume that each pathway, which can be viewed as a func- tional unit of gene expression, is represented by the LDR feature that leads to the highest average ranking of the genes in it.

Although expression samples used in VAE train- ing were obtained from many different studies, DeepProfile successfully disentangles data discrepancies and learns an informative LDR that accurately predicts complex pheno- types for different cancers. Our



Palla et al. 2020

Latent factor modeling applied to single-cell RNA sequencing (scRNA-seq) data is a useful approach to discover gene signatures. However, it is often unclear what methods are best suited for specific tasks and how latent factors should be interpreted.

we compare four state-of-the-art methods and propose an approach to assign derived latent factors to pathway activities and specific cell subsets.

. Phenotypic identification of clusters is usually performed by means of a hybrid approach that entails prior knowledge of the biological system and gene set enrich- ment analysis on cluster markers.

An alternative, cluster-free approach to phenotypic identification of cellular states is trajectory analysis (Saelens et al., 2019), which aims to derive differentiation processes by using a pseudo-temporal ordering of single cells.

Latent factor models aim to decompose the global expression profile in its underlying transcriptional pro- grams (Stein-O’Brien et al., 2018).

Standard matrix factorization approaches, such as principal component analysis (PCA), non- negative matrix factorization (NMF), and independent component analysis (ICA), have been widely applied to scRNA-seq data (Kotliar et al., 2019)

novel methods have been developed that account for the specificities of single-cell data, using meaningful prior distributions and enforcing sparsity 

different biological processes are captured at different dimensionalities of the latent space (Way et al., 2020), suggesting that approaches considering a varying number of latent dimensions could be more robust in fully recapitulating the underlying biology of the dataset under consideration.

a systematic comparison of four recent latent factor models that specifically account for the spar- sity of scRNA-seq data: scCoGAPS (Stein-O’Brien et al., 2019), LDA (Bielecki et al., 2018; Dey et al., 2017), scHPF (Levitin et al., 2019), and scVI (Lopez et al., 2018; Svensson et al., 2020). The first three methods are built on probabilistic approaches to matrix factorization and have been successfully used to extract gene signatures from scRNA-seq data (Clark et al., 2019; Svensson et al., 2020; Xu et al., 2019; Zhao et al., 2020), whereas the last one is based on a deep variational autoencoder with a linear decoder, making the inferred gene weights interpretable (Svensson et al., 2020)

Reasoning that latent factors can be used as surrogates of pathway activities, we devise a simple method to assign gene signatures to cell clusters, thus enabling the identification of cell subsets from a functional perspective.

we explore the reported gene signatures and discover two previously uniden- tified pathways in the RA dataset: the OSMR signaling pathway in a subpopulation of fibroblasts and the MERTK signaling pathway in a monocyte subset. We show that these signatures are potentially disease associated, t

A common heuristics to select an appropriate latent dimension is to calculate the algorithm’s stability across iterations and select the number of dimensions with results that are more consistent across iterations

To assess whether these latent factors retained information onthe diseasestate of thesamples,weused them as predictors of an elastic net regression model with the task of classifying disease and control cells

The ability of latent factor models to recover biological signal is a key feature in their application to discover cellular phenotypes. Gene set enrichment analysis is a widely used approach for this task, as it allows map- ping each latent variable to a specific pathway or biological process. To

To evaluate the methods’ ability to recapitulate biologically meaningful gene signatures in a systematic manner, we used an enrichment approach based on heterogeneous network (Himmelstein et al., 2017; Way et al., 2020). Briefly, at each dimensionality of thelatentspace,wecompute thegeneset coverage score(numberofunique gene sets significantly associated with each latent variable divided by the total number of gene set in the collec- tion) for the gene set collection of interest 

By comparing the gene set coverage on the latent variables with the standard enrichment on clusters’ marker genes (Figure S1E), we showed that the number of significant gene sets is an order of magnitude higher for the factorization methods, pointing to a higher sensitivity in the discovery of pathway activities. Interestingly,

the phenotypic identification of cell populations after clustering. Usually, this is performed by means of a combination of prior knowledge of cell-specific markers and gene set enrichment analysis performed on the marker genes list for each cell subset

as latent variables provide a surrogate of pathway activities across cells, we devised a simple framework to assign each pathway to cell clusters (Figure 2A). This approach directly allows the identification of cell subsets in a function- or phenotype-driven way. Briefly, we start by employing a stan- dard clustering procedure to identify cell subsets (see Methods). For each gene set, we collapse redundant assignments to multiple latent variables in unique pathway activities, by means of an iterative clustering approach. Then, we regress pathway activity weights (i.e., the numerical results of the factorization) using the cell cluster labels as predictors. The coefficient of each cluster represents an indicator of how important that cell subset is to explain the pathway activity, therefore linking the activity of the pathway to the cell cluster, which can then be functionally interpreted. The

broadly defined cell populations cluster together, showing that consistent activities across different biological processes recapitulate cell lineages.

this approach allows discovery of pathway activities that are unique to specific cell types or that are shared across different cell subsets in an unsupervised way.

This strategy can also be used to annotate known, yet unidentified, cell types

this framework to define pathway activities is a powerful approach to assign cell identity and cell states to clusters based on their function or phenotype

By using latent variables as surrogates of pathway activities, we sought to discover novel pathways poten- tially involved in RA.

 latent factors enriched for OSMR signaling-related gene sets. We

To further explore the potential of pathway activities to uncover novel gene signatures, we sought to inte- grate this information with ligand-receptor interaction analysis (see

the expression level of interacting ligands and receptors was correlated with, and filtered for, latent variables with a significant enrichment for pathways where either protein was present (Figure

Gene set coverage evaluation: Gene set coverage score was computed by means of heterogeneous networks (Himmelstein et al., n.d.), as described in Way et al (Way et al., 2020) . Briefly, we made use of heterogeneous network made available by Way et al. or generated as part of this study from several gene set collections (MSigDB (Liberzon et al., 2011), KEGG (Kanehisa and Goto, 2000), REACTOME (Jassal et al., 2020), Biocarta, MetaBase (Clarivate Analytics MetaBase® version 6.15.62452), WikiPathways (Slenter et al., 2018)). We also generated respective shuffled networks in order to calculate a z-score for each gene set – latent variable pair. We then converted the z-scores to p-values and applied a Bonferroni correction. Gene sets were considered significant if their p-value was lower than 0.01 divided by the number of latent variables for the specific latent space dimensionality. For each gene set collection and each latent variable, the top gene set was selected to be mapped to that latent variable. Ultimately, for each model, we would have at most an equal number of gene sets according to the dimensionality of the latent space. The number of unique gene sets was then used to calculate the coverage score (number of unique gene sets divided by the number of total gene sets in that collection). In

Gene set assignment to cell clusters: After matching each latent variable to its most significant gene set in each collection, we reasoned that we could use the latent variable as a surrogate of the respective pathway activity. Furthermore, we decided to use all the latent variables derived by the models, without selecting a single dimensionality of the latent space.  To account for the duplicated instances of the gene sets (same gene set mapped to multiple latent variables), we implemented a simple iterative algorithm. Furthermore, we devised an approach to assign these pathway activities to cell clusters: each pathway activity was set as the response variable in a regression setting where the cluster labels function as the predictors. Thus, a cell cluster that comprises several cells that have a high weight for that specific latent variable, would also be assigned a large coefficient



Culley et al. 2020 - NOT REALLY BIO INFORMED

We propose, rigorously assess, and compare machine-learning– based data integration techniques, combining gene expression profiles with computationally generated metabolic flux data to predict yeast cell growth. To

we create strain-specific metabolic models for 1,143 Saccharomyces cerevisiae mutants and we test 27 machine-learning methods, incorporating state- of-the-art feature selection and multiview learning approaches

We propose a multiview neural network using fluxomic and transcriptomic data, showing that the former increases the pre- dictive accuracy of the latter and reveals functional patterns that are not directly deducible from gene expression alone. We

introducing mechanistic flux features improves the predic- tions also for knockout strains whose genes were not modeled in the metabolic reconstruction

We propose and test a machine-learning approach that integrates large-scale gene expression pro- files and mechanistic metabolic models, for characterizing cell growth and understanding its driving mechanisms in Saccharomyces cerevisiae. At

We show that our approach can lever- age the advantages of both machine learning and metabolic modeling, revealing unknown interactions between biological domains, incorporating mechanistic knowledge, and therefore overcoming black-box limitations of conventional data-driven approaches.

Our idea is that reconnecting metabolic activity to cell growth
with a data-driven and multiview approach should support more accurate machine-learning predictions, while incorporating bio- logical mechanisms within the learning process. To

we used a compendium of 1,143 single-gene knockout S. cerevisiae strains, with their genome-wide expression profiles as training data to build models that predict cell doubling times

We augmented the array of biological predictors by incorporat- ing a metabolic modeling phase, wherein we use transcriptomic profile integration in CBM to simulate strain-specific metabolism using parsimonious flux balance analysis (pFBA). From these simulations, we extracted reaction fluxes as additional features (fluxomic data).

We then applied machine-learning methods using the transcriptomic and fluxomic datasets combined across 27 data–method combinations, testing different approaches for their multiview integration. 

When the integration of the two omics was performed within a neural network architecture, we found a significant improvement compared to using transcrip- tomic data alone.

we explored three traditional machine-learning tech-
niques

1) support vector regression (SVR)—often the learning tool of choice in computational biology due to its non- linear decision boundary and ability to handle high-dimensional datasets

2) random forest (RF)—able to handle hetero- geneous data types in high dimensions and to account for both correlation and interaction among features, which has led to suc- cess in predictive modeling in multiple biological domains

3) artificial neural networks (ANNs)—extremely effective in learning and modeling complex systems

We applied these methods to GE, MGE, and MF data separately, in a single-view fashion, to obtain a baseline performance for the following steps.

In a second stage, we studied the integration of base omic datasets. Because our combined data represent two distinct views on the same biological systems, to thoroughly investigate the use of complementary information we explored three data strategies

1) early integration, where GE and MF are concatenated and treated as a single dataset

2) intermediate integration, where model building is carried out on a combined transformation of the input views;

3) late integration, where a model is separately built within each view and then the models are fused (3).

For intermediate and late integration, we used three multiview methods based on those employed in the single-view scenario

1. Bayesian efficient multiple-kernel learning (BEMKL) (40), applying separate radial basis kernels to the MF and GE datasets.
2. bagged random forest (BRF) with distinct forests learned on transcriptomic and fluxomic pro- files

3. multimodal artificial neural network (MMANN) to independently extract latent information from the two omic views and then fuse it together via additional neural layers

a flux-coupling analysis to iden-
tify reaction fluxes on which growth rate is mutually dependent (fully coupled) or unilaterally dependent (directionally coupled)

given the high prediction accuracy of MMANN mod-
els, we sought to determine their most contributing features. To this end, we exploited recent advances in ANN interpre- tation via the SHapley Additive exPlanations (SHAP) method (51), a general approach for determining the contribution (called SHAP value) of individual features to model outputs.



Seninge et al. 2020

we introduce a novel sparse Variational Autoencoder architecture, VEGA (Vae Enhanced by Gene Annotations), whose decoder wiring is inspired by a priori characterized biological abstractions, providing direct interpretability to the latent variables.

We demonstrate the interpretability and flexibility of VEGA in diverse biological contexts, by integrating various sources of biological abstractions such as pathways, gene regulatory networks and cell type identities in the latent space of our model.

our model could recapitulate the mechanism of cellular-specific response to treatments, the status of master regulators as well as jointly investigate the cell type and cellular state identity in developing cells.

We envision the approach could serve as an explanatory biological model in contexts such as development and drug treatment experiments

VEGA (Vae Enhanced by Gene Annotations), a Variational Autoencoder with a sparse linear decoder informed by biological networks. 

 This model aims at offering an interpretable latent space to represent various biological information, e.g. the status of biological pathways or activity of transcriptional regulators. 

Specifically, the scope of our model is twofold, (1) encoding data over an interpretable latent space and (2) inferring biological information for out-of-sample data

a novel architecture inspired by biological abstractions,

VAE latent variables are in general hard to interpret. To interpret VAE latent variables, Svensson et al. proposed to investigate the corresponding weights towards original variables, similarly to the interpretability offered by standard factor models such as PCA 11
.Although providing valuable insights in interpreting single cell biology,
such an approach requires further statistical analyses on the weights of the decoder.

The generative part of our model (decoder) directly relates the latent variables (biological abstractions, such as gene-regulatory networks) and the original gene features: a dependency between gene k and latent variable z (l)
exists if and only if gene k is a priori annotated as part of
biological abstraction l . This relies on the fundamental assumption that a set of known biological modules underlies and orchestrates the gene expression patterns of a given scRNA-Seq dataset.

The annotation can come from curated databases such as MSigDB 12
, inferred
gene-regulatory networks 13
, or any other pre-defined gene set.

. Such a design presents two
main advantages: (1) the latent variables are initialized a priori therefore directly interpretable as the activity of biological modules, and (2) the flexibility in the biological module specification makes it generalizable to different biological abstractions

When initializing the architecture of such a model, it is possible to model the dependency between biological modules to the original features in the inference network (encoder), the generative network (decoder), or both. Our choice of using a deep encoder, sparse linear decoder structure can be justified by the goal of increasing the inference capacity of our model: it can capture more complex patterns in its interpretable latent space when approximating the true posterior distribution P(z i
|x i ) over biological modules, while the link between latent variables
and original gene features is guaranteed by the sparse linear decoder part of the neural network

our model is able
to capture cell types and stimulation status using the reactome pathways as latent variables

confirming the ability of our model to capture pathway activity in its latent space

the
ability of the model to project cells in an interpretable space, allowing investigation of cell-type specific patterns at the cellular process level.

a similar procedure to study the difference in
biological module activity based on the latent space of our model: we can formulate alternative hypotheses and compute the ratio of their posterior probabilities using the variational posterior distribution of our model, which corresponds to the Bayes Factor (

pathways that are expected to be activated in the stimulated groups (interferon signaling, tryptophan catabolism) are found to be significant by our method

VEGA does not seem to suffer as much from the gene set size bias problem inherent to GSEA

whether our model could capture and recapitulate patterns of drug responses in large-scale experiments over cancer cell lines

we sought to investigate whether we could recapitulate the
pattern of biological responses between control and treated conditions for each cell line/drug treatment pair. For each pair, we computed the Bayes Factor of each latent variable (pathway) in our models. The resulting heatmap can be used to understand and interpret patterns of response over all experimental conditions (Fig.2C).

, one of the major strengths of our model is the flexibility in the latent space specification, as any biological module can be related to a gene set and therefore be encoded in our model.

we investigated whether using master regulators to specify the latent space of our model could help understand the underlying gene regulatory networks (GRN) in the context of a single-cell glioblastoma (GBM) dataset 25
.

We used the GBM ARACNe 13 network reported in 24
to guide the structural design of our model. Specifically, the transcription factors were used to initialize the latent space of our model, and the transcriptional factor-target connections were used initializing the decoder wiring.

After training the model, we show that pre-annotated cell types can be recapitulated in the latent space (Fig.2D).

the flexibility and extensibility of our method in the specification of the latent space and decoder wiring. Furthermore, these results demonstrate the ability of our model to faithfully represent biological information.

we investigated whether we could combine information about cell types (in the form of marker sets defined as lists of marker genes) and cell states (reactome pathways) in the latent space of our model, to produce a disentangled representation of cell types and cellular states

including the information about the major
cell types defined in the study in the latent space

the activity of each cell type marker set was able to correctly segregate its corresponding cell type as annotated by

in a “one vs. rest” differential factor analysis setting for each cell type population, the activity of the corresponding marker set showed a significant enrichment (|log e
(BF)| > 3), potentially showing the opportunity for researchers to use the latent
activity of cell type marker sets to annotate unknown clusters (Fig.3E).

To study whether our model could separate cell type identity from cellular states such as dividing versus quiescent cell populations, we projected the dataset into two components: (1) the neural epithelium marker set activity (a type of early brain progenitor) and (2) the cell cycle mitotic pathway activity

Together, these results demonstrate
the potential use of our model to jointly infer cell type and cellular state identity for different populations of cells, as combining different sources of information (pathways, master regulators, cell type markers) in the latent space of our model can shed light on different aspects of the identity of a single-cell.

our model can be used to infer an interpretable latent representation of data unseen at the time of training, which we refer to as out-of-sample data

To confirm the generalizability, we evaluate our model in two settings: (1) the “biological generalization” of the inference, where a certain cell type/condition pair is left out during training (intra-dataset setting)

 (2) the “technical generalization” of the inference, where a model trained on the Kang et al. 14 PBMC dataset
(which we refer to as study A) is evaluated on another PBMC dataset containing only control cells from Zheng et al. 28
(study B, inter-dataset setting).

hese results together show the ability of the model to infer an interpretable latent space for data unseen at the time of training, with some limitations coming from potential batch effects. This could be easily alleviated by re-training the model on the new data, as this procedure is quite fast.

, VEGA, whose decoder wiring is inspired by known biology to infer the activity of various biological modules at the single-cell level. By encoding single-cell transcriptomics data into an interpretable latent space specified a priori, our method provides a fast and efficient way of analyzing the activity of various biological abstractions in different contexts.

our model could be useful to prioritize drugs based on pathway expression in cancer, as studying the response of specific cell populations can be useful to understand drug sensitivity and resistance. Integrating drug response prediction models with explanatory models like ours could be highly beneficial in designing novel therapeutic strategies. Furthermore, we also speculate that our interpretable VAE will provide insights in understanding general biological questions

The flexibility in the specification of the latent space paves the way for analyzing the activity of biological modules such as pathways, transcriptional regulators and even cell type-specific modules

our model could be used to explore together the cell type and cell state of various subpopulations of cells, whether it is in the context of perturbation experiments or not.

the weights of decoder connections provide direct interpretability of the relationship between the latent variables and the original features. For example, it could be used to contrast interaction confidence in inferred gene-regulatory networks, or rank genes by their importance in a certain biological module in a data-driven way

The clear limitations of the current architecture resides in the sparse, single-layer decoder of the model. In fact, such an architectural design prevents the further improvement of generalizability and robustness.

the generative capacity of our VAE is undermined. For example, while theoretically our model could be used for interpretable response prediction using latent vector arithmetics in a similar fashion to scGen 10
, the limited generative capacity of our
approach sacrifices predictive performance for interpretability. Our design choices therefore compromise those aspects for biological interpretability of the latent space.

hard-coded connections of the linear decoder does not leave any room for correcting prior knowledge about biological factors when the context requires it, as is the case in other latent variable models such as f-scLVM 29

prior biological knowledge obtained
from existing databases like MSigDB can be incomplete or not context-specific, as additional unannotated genes can play an important role in certain biological factors

VEGA architecture: we choose to have our set of latent variables Z explicitly represent biological abstractions, such as pathways, gene regulatory networks or cell type marker sets.

To enforce this, we modify the decoder part of the VAE architecture to be a single layer, masked, linear decoder. Specifically, the connection of this layer, between latent node z (j)
and input gene features, are specified using a mask M , which is a
binary matrix (1 if the gene is a member of gene set, 0 otherwise)

we zero-out gradients associated with masked weights, such that backpropagation only applies to weights originating from a priori annotation, while the rests of the weights are kept at 0. Additionally, the decoder is constrained to positive weights ( w ≥ 0) , to maintain interpretability as to the directionality of the biological module activity. Having explicitly specified the connections between genes and latent variables in the generative part of our model, we ensure that the latent space represents biological module activity, as well as its interpretability.

To retain information of genes that are not present in our pre-annotated biological networks, we add additional fully-connected nodes to the latent space of our model. This has two effects: (1) it allows to model the expression of unannotated genes, crucial for a good reconstruction of the data during training, and (2) it can help capture additional variance of the data that is unexplained by the existing biological factors, considerably improving the training of the model.

Bayesian differential factor activity: study the difference in factor activation between two groups of cells and its significance. This can intuitively be seen as testing whether a cell has a higher mean biological factor activation than another, the expectation representing empirical frequency. We evaluate the most probable hypothesis by studying the log-Bayes factor K 

the sign of K tells us which hypothesis is more likely, and the magnitude of K encodes a significance level. Having access to the conditional posterior distribution q(Z|X) over the factor activation (the inference part of our model), we can approximate each hypothesis probability distribution as:

assuming cells are independent, we can compute the average Bayes factor
across many cell pairs randomly sampled from each group respectively. This helps us decide whether a factor is activated at a higher frequency in one group or the other. T



Xue and Lu 2020   INTERESTING BUT NOT REALLY BIOINFORMED

we investigated the capability of deep generative models (DGMs) to modeling signaling systems and learn representations of cellular states underlying transcriptomic responses to diverse perturbations. Specifically, we show that the variational autoencoder and the supervised vector-quantized variational autoencoder can accurately regenerate gene expression data in response to perturbagen treatments. The

The models can learn representations that reveal the relationships between different classes of perturbagens and enable mappings between drugs and their target genes. In summary, DGMs can adequately learn and depict how cellular signals are encoded. The

DGMs are a family of deep learning models that employ a set of hierarchically organized latent variables to learn the joint distribution of a set of observed variables. After training, DGMs are capable of generating simulated data that preserve the same compositional statistical structure as the training data. 

The hierarchical organization of latent variables is particularly suitable for representing cellular signaling cascades and detecting compositional statistical patterns derived from perturbing differ- ent components of cellular systems. The

The capability to “generate” samples similar to the training data are of particular interest. If a model can accurately regenerate transcriptomic data produced under different perturbations, the model should have learned a representation of the cellular signaling system that enables it to encode responses to perturbations. Such representations could shed light on the MOAs [mechanisms of action] through which perturbagens impact different cellular processes.

the VAEs can reconstruct the LINCS data accurately and also generate new data that are indistinguishable from real observed data. We

by adding a supervised learning component to vector-quantized VAE (VQ-VAE)18, we are able to summarize the common features of a family of drugs into a single embedding vector and use these vectors to reveal relationships between different families of drugs.

S-VQ-VAE is an extension of VQ-VAE where the training of the embedding space is guided by the label of the input data. Similar to VAE, an input case is first transformed into an encoding vector ze xðÞ by the encoder. During training, the encoding vector is replaced by the embedding vector ey designated to represent the label y of data to reconstruct the input case. The embedding vector is updated according to the reconstruction error. During testing, the encoding vector is replaced by the nearest neighbor embedding vector ek.

DGMs for learning how cellular signals are encoded in response to perturbations. Our

the use of DGMs as a powerful tool in modeling cell signaling systems.

The input and output layers contained 978 nodes, each corresponding to one of the 978 landmark genes in an L1000 expression profile. The internal architecture is composed of three hidden layers in its encoder, with 1000, 1000, and 100 hidden nodes, respectively (Supplementary Fig. 1); the decoder has a reverse architecture as the encoder

To gain a better understanding of how VAEs encode the distribution of diverse input data, we next examined the activation
patterns of hidden nodes on different layers of the SMGP-trained VAE model. We paid particular attention to the top hidden layer of 100 nodes that serves as an “information bottleneck” for compressing the original data, because this layer also serves as the starting point for the generation of new samples.

We found that 12 out of 100 nodes in the encoding vector had a high variance in activation values across samples

For an ordinary VAE model, the prior distribution of the encoding vector is a standard normal distribution with a mean vector μ xðÞ ¼ 0 and a diagonal covariance matrix Σ xðÞ ¼ diagð1Þ

During training, an element of the vector shrinks towards 0 unless it is driven by data to deviate from 0. Therefore, the significantly high absolute values taken by these 12 hidden nodes suggest that they encode major signals of input data. From this point forward, we refer to these 12 hidden nodes as the signature nodes

we fed the samples treated with perturbagens of the class through the trained VAE encoder and took the average signature node values across samples as a vector representation of the PCL. As

To further demonstrate that the primary characteristics of an expression profile are encoded in the 12 signature nodes, we generated new expression profiles to simulate samples treated with a target PCL by manipulating values of the signature nodes to mimic the patterns found the previous experiment We preset the signature nodes to values similar to the average values of training samples treated with the target PCL as shown in Fig. 3b and randomly initialized the other hidden nodes from a standard normal distribution. In this manner, we randomly generated 500 new samples using the VAE decoder for eight major PCLs. We then compared the randomly generated samples against real samples to see whether their nearest neighbors were from the target PCL

signature node pattern reflects a specific cellular signaling process, which, after decoding, generates an expression profile that may reflects how the signaling is perturbed

The signature node representations of PCLs discussed above were obtained by averaging over samples treated with small-molecule perturbagens of a PCL

In order to learn a unique, stable global representation for each PCL, we designed another DGM, the S-VQ- VAE, which utilizes the PCL class labels of perturbagens to partially supervise the training process. S-VQ-VAE was extended from VQ- VAE by utilizing the vector-quantized (VQ) technique to discretize the encoding vector space into multiple mutually exclusive subspaces represented by a limited number of embedding vectors and projecting data from each class into its pre-assigned subspace. After training, each embedding vector learns to summarize the global characteristics of a class of data. 

In this study, we used S-VQ-VAE to learn an embedding vector with a dimension of 1000 for representing each of the 75 PCLs in the SMC dataset

We utilized the embedding vectors to reveal similarities and potential functional relationships between PCLs by comparing each PCL to all the others to identify its nearest neighbor based on Pearson correlation. Some strong relationships, like bi-directional connections are observed (Fig. 5), and many such relationships correspond to well- documented shared MOAs between the drugs in the connected PCLs.

the global representations learned with S-VQ-VAE preserve crucial informa- tion that reveals the functional impact of different PCLs.

we next investigated the information preserved in the latent variables of different hidden layers of the SMGP-trained VAE. To do this, we first represented the SMC samples with seven types of representations, including the raw expression profiles, the latent representations obtained from the five hidden layers of the VAE (across the encoder and decoder), and the 12 signature node values

VAEs can encode the impact of different drugs within different layers in the hierarchy that potentially reflect the relative level of drug-target interactions in the cellular signaling network.

Most drugs have their best performance achieved with VAE-learned latent representa- tions rather than the raw expression profiles, and for five drugs, the best performance was achieved with the 12-signature-node- representation. Table

the best aggregation performance was achieved with latent representations rather than the raw expression profile, which also supports that latent representations are better at revealing drug-target relations.

the trained VAE and S-VQ-VAE models were able to accurately regenerate transcriptomic profiles almost indistinguish- able from the input data. These results are intriguing because they suggest that the DGMs may have captured signals of cellular processes underlying the statistical structures of the data. Such

in its original form, VAE cannot utilize additional information aside from data passed from the input layer.

The S-VQ-VAE model is an early attempt toward the goal of combining different information sources. It utilizes additional label information to facilitate the learning of global representations, but essentially it does not directly combine multiple types of data nor realize a fully interpretable multi-task learning. 

S-VQ-VAE is a new DGM designed in this study for learning a vector representation (embedding) for each PCL. 

The model was extended from the standard VQ-VAE18 by adding a supervised mapping step to guide the training of the embedding space.

Like VQ-VAE, a S-VQ-VAE is composed of three parts, an encoder neural network to generate the encoding vector  zeðxÞ given an input vector x, an embedding space to look up the discrete representation zqðxÞ based on zeðxÞ, and a decoder neural network to reconstruct the input data from zq(x)

the embedding space E is defined as E 2 RY ´D, where Y is the number of different classes of the input data. In our case, this corresponds to PCLs. Each of the Y embedding vectors of dimension D is designated to learn a global representation of one of the classes.

In forward computation, an input x is first converted to its encoding vector zeðxÞ, which will be used to update the embedding space.  In the training phase, zeðxÞ is replaced with zq xðÞ ¼ ey to pass to the decoder, where ey is the embedding vectors of the class y of x. In the  testing phase, zeðxÞ is replaced by its nearest code zq xðÞ ¼ ek 

we are not assuming a uniform distribution of the embedding
vectors as in the ordinary VQ-VAE18. Instead, the distribution of codes is determined by the input data with its discrete class labeling governing by a multinomial distribution

the objective function of S-VQ-VAE contains a reconstruction loss to optimize the encoder and decoder (first term in Eq. (2)), and a dictionary learning loss to update the embedding space (second term in Eq. (2)).

The data generation process is composed of two steps, similar to the ancestral sampling method. First, sample a target class y from the distribution of classes of the input data. Second, sample an encoding vector z ? Nðey; σ2Þ, where σ2 is the covariance matrix of hidden variables estimated from the training data of class y. A new sample of class y can then be generated by passing z to the decoder of S-VQ-VAE. 

The generation process reflects another advantage of S-VQ-VAE compared to unsupervised GMs: we can determine what content the new data should present rather than interpret it afterward

To see how S-VQ-VAE can be used as a general generative model, please refer to our tutorial of S-VQ-VAE at https://github.com/evasnow1992/S-VQ-VAE, where



Hanczar et al. 2020

We focus on explaining the predictions of a deep neural network model built from gene expression data. The most important neurons and genes influencing the predictions are identified and linked to biological knowledge. Our

We propose an original approach for biological interpretation of deep learning models for phenotype prediction from gene expression data. Since the model can find relationships between the phenotype and gene expression, we may assume that there is a link between the identified genes and the phenotype. The interpretation can, therefore, lead to new biological hypotheses to be investigated by biologists.

Two types of interpretation may be identified [13, 14]: prediction interpretation and model interpretation

The predic- tion interpretation consists of explaining the prediction of a specific input

model interpretation explains the logic behind the model when predicting the dif- ferent outputs on the whole population

The interpretation of neural networks built from gene expression has not been thoroughly studied. The majority of the published works focuses on the identification of the genes that impacted the prediction but does not investigate the representation of the gene expression learned in the hidden layer. For

For example, Danaee and Ghaeinix [15] identified relevant genes for the diagnosis of breast cancer using stacked denois- ing autoencoders. The relevant genes are those with a strongly propagated influence on the reduced dimension of the network and are analyzed using the Kyoto Encyclo- pedia of Genes and Genomes (KEGG) and Gene Ontology (GO). The aim of all these studies is to identify potentially interesting genes related to the disease of interest

, they do not explain what the network does, or what represents a neuron, or what representation of the patient is constructed in the hidden layers. Very few works tried to interpret the hidden neurons and almost all of them are based on the analysis of the values or the distribution of connection weights of the learned neural network [16]. Way

Way et al. [8] analyzed the decoder’s connections of their variational autoen- coder and associate each neuron to the set of genes with the highest absolute values of weight. Based on these gene sets, they applied an enrichment analysis to identify overrepresented pathways and GO biological process terms to each neuron. In

In [16], authors built denoising autoencoders and stacked denoising autoencoders to extract important genes from cancer gene expression dataset. The importance of genes is defined as the sum of their outgoing connections. A subset of the most important genes is selected and then analyzed by performing a functional annotation analysis.

Sharifi et al. [7] studied the distribution of the output weights of each neuron in order to estimate their significance for the prediction of the metastatic tumor

Recent works in the machine learning community show that the use of gradient meth-
ods produces better interpretations of a neural network than an analysis of their weights

Lundberg and Lee [23] showed that among gradient models DeepLift and LRP are better aligned with human intuition as measured by stud- ies since they satisfy some desirable properties. To

, only one paper used the integrated gradient method to identify the most important genes related to a low- dimensional representation space (LDR) learned using a variational autoencoder [9 = Dincer DeepProfile]

Our approach adapts gradient based approaches of neural network interpretation in order to identify the important neurons i.e. the most involved in the predictions. Then all these important neurons are associated with genes, biological functions and metabolic pathways. Our experiments on cancer prediction show that our approach produces more relevant inter- pretation than the state of the art based on weight analysis.

a deep multilayer perceptron with an input layer of 54675 neurons, three hidden layers of 500, 200, 50 neurons respectively and an output layer of two neurons corresponding to the non-cancer and cancer classes. To

In order to interpret the learned model, the relevance vector of each example in the test set is computed

The relevance vector of an example contains the relevance score, com- puted by LRP, of all neurons of the network. Note

LRP is applied from the output neuron corresponding to the predicted class. A relevance vector represents therefore which part of the network is the most responsible for the prediction of a given example.

An analysis of these individual relevance vectors shows that, for almost all of the exam- ples, only a small set of neurons is important, i.e. have a high relevance score. H

the clustering based on the relevance vectors does not overlap with the clustering based on the gene expression profiles. Examples

An interesting observation is that the prediction errors tend to be grouped in some
clusters. This means that the error of predictions often comes from the same set of neurons. Therefore, the network contains some paths of propagation that lead to less confident predictions.

If we look at the distribution of the examples on the dendrogram according to the type of tissue, we do not observe any particular pattern. The

the way an example is propagated through the network does not depend on the tissue. Two explanations are possible.

1. the network has discovered a general signature of cancer for any type of tissue. 
2. t the network found different signatures for the different tissues but these signatures are merged into the same set of neurons.

In the majority of NN interpretation works for gene expression, the evaluation of the impact of a neuron (input or hidden) is based on the weight average of their output con- nections (WM). However, in many situations, the WM score does not represent the real contribution of an input or neuron to the prediction

The LRP relevances can be considered as a better representation of the real impact of the input on the output than the WM values since the latter is independent from the input data. By

By definition WM values are computed only from the weights of the connections. These values could repre- sent the importance of the inputs if the variables were independent and uniformly distributed. However, this is not the case in the context of gene expression data. The interpretation must depend on the distribution of the data that are provided to the network.

we meas- ure the consistency of the LRP and WM interpretations of our cancer prediction network with known biological knowledge

t the p-values obtained from the LRP selection are much smaller than the p-values given by WM selections. The obtained values are around 0.05, except for k = 300, 500 . This shows that there is an over-representation of the genes linked to cancer in the set of genes with the highest impact on the prediction of cancer. In other words, these results show that our network mainly uses genes, that are known to be related to cancer, to make cancer predictions

These results show that the LRP produces more relevant interpretation than WM, the LRP p-values are much lower than the WM p-values. WM is data inde- pendent, the produced interpretation is therefore very general. Since LRP computes a relevance score for each example, it leads to more relevant interpretations

the interest of our method by providing a biological inter- pretation of the neural network predicting cancer from the previous section. F

The important neurons of layer 1 can be grouped into subgroups depending on the
functions enriched among the important genes they contain. Overall, the enriched func- tions belonged to three main categories which are the cell cycle, metabolic processes, morphogenesis even though the three are linked. The

Neurons 26 is the only neuron that focuses solely on cell cycle pathways. It is associated with a list of 593 genes. The most enriched GO terms are mitotic cell cycle process, GO:1903047, and mitotic cell cycle, GO:0000278 with the other important enriched GO terms in this neuron all belonging to mitotic division and DNA replication. This neuron hence specialized in detecting genes in relation to cell proliferation, an essential element in cancer as cancer originates from uncontrol- lable growth of abnormal, mutated cells. The KEGG enrichment analysis of this neuron showed that among the most enriched metabolic pathways are the ones in which mitosis and DNA replication are involved such as cell cycle, which is the cell division cycle in general and the focal adhesion pathway which regulates the cell cycle pathway

In the second hidden layer of the network, we had 7 important neurons. Among them
is neuron 183 which is one of the most significant neurons of layer 2. It was found to have an important link with neuron 26 of the first hidden layer. When looking at the GO terms enriched at this level, we see that the most enriched one is regulation of chromo- some segregation, GO:0051983, which regulates the separation of the genetic material. Other enriched GO terms are also linked to chromosome segregation and cell division.

the goal of the interpretation is to explain how the model works and not how biology works. Sometimes, there is no obvious relation between the biologi- cal functions or metabolic pathways, returned by the interpretation, and the predicted phenotype. This does not necessarily mean that the predictions are not reliable.

the different types of conclusions that we can draw from a bio-
logical interpretation of a model. We identify three cases based on the results of the interpretation. In

1. In the first case, the majority of the elements provided by the biologi- cal interpretation are related to the predicted phenotype. This means that the model bases its predictions on elements consistent with the biological knowledge. This should improve the trust in the model in addition to its prediction performance. 
2. The second case is the opposite. Most parts of the elements provided by the biological interpreta- tion are known to be unrelated to the predicted phenotype. Since the predictions are based on elements inconsistent with the current biological knowledge, the reliability of the model must be questioned. The model may overfit or be misled by a bias in the train- ing set. 
3. In the last case, the biological interpretation mostly provides elements that may or may not be related to the predicted phenotype. Interpretation does not help to evalu- ate the trust that we can place in the model. However, in this case, we can use the inter- pretation as a tool for biological discovery. Since the model finds a relationship between the phenotype and gene expression based on the elements identified by the interpre- tation, we can assume that there is a link between these elements and the phenotype Interpretation can therefore lead to new biological hypotheses to be investigated by biologists.

to identify the neurons and inputs of the NN that contribute to the predictions and to link them to biological knowledge. The model is reduced to a sub-network con- taining the relevant connections and neurons involved in the prediction. These neurons are then associated with a list of genes and the corresponding biological knowledge (GO, KEGG, and DOLite). O

We present the deep neural network architecture used for gene expression data and our biological interpretation approach. The gradient method for neural network interpre- tation is the Layer-wise Relevance Propagation (LRP), which is adapted to identify the most important neurons that lead to the prediction as well as the identification of the set of genes that activate these important neurons. Finally, the important neurons and genes are linked to the Gene Ontology (GO), the Kyoto Encyclopedia of Genes and Genomes (KEGG) and the Disease Ontology Annotation List (DOLite) in order to propose a bio- logical interpretation of the neural network model.

we chose the LRP [18] for two reasons: firstly LRP produces results well aligned with human intuition [23], secondly it does not need reference inputs

The idea of LRP is to backpropagate the signal of the output neuron of interest through
the network. For a given output neuron, at each layer l, the relevance score of each neu- ron and each connection is computed from the relevance scores of the layer ( l + 1 ). These relevance values represent how the neurons and connections have contributed to the activation of the studied output neuron

. This method is based on layer-wise conser- vation principle that forces the preservation of the propagated relevance between layers and neurons i.e. the sum of neuron relevance is constant through all layers and for each neuron the sum of output connection relevance is equal to the sum of input connection relevance.

The relevance of a neuron is defined by the sum of the relevances of all its output connections:

Originally, LRP has been developed to interpret the prediction from images i.e. esti-
mate the contribution of each pixel to the prediction of the class of a given image. In this work, we adapt and use LRP in the context of gene expression data. Moreover, our work focuses on the problem of model interpretation rather than prediction interpretation. Our analysis is therefore based on the average of relevances computed from a subset of the test sets and not on individual relevance scores. The LRP can also be used to explain the individual prediction but this analysis is out of the scope of this paper.

The objective is to identify the biological functions and metabolic pathways that the neural network uses to predict each class. For each class the proposed interpretation approach can be decomposed into three steps (see Fig. 7).

1. In the first step, we compute the relevance scores through the network and identify the most important neurons that allow predicting the class. 
2. Then, we associate with each important neuron a list of the significant genes affecting the neuron activation. 
3. Finally, biological functions, metabolic pathways and diseases are associated with each important neuron.
   Selection

The first step is to identify the neurons that most influence the predictions for each class. For this, we compute the relevance scores of all neurons for each prediction using the LRP procedure. These relevance scores associated with individual predictions are used to compute the model scores for each predicted class.

LRP was conceived to associate relevant inputs to the prediction. In this step of our approach, we propose to associate with each important neuron the list of the genes that influence the activation of the neuron.

We can see the activation of a neuron as a non linear representation of the expression of the set of its associated genes. In order to associate each important neuron to a list of genes, we annotated the input with their GenBank accession number.

The final step of our approach is to associate each important neuron to biological func- tions from Gene Ontology (GO), metabolic pathways from the Kyoto Encyclopedia of Genes and Genomes (KEGG) and diseases from Disease Ontology Annotation List (DOLite). For each neuron, we identify the over-represented GO functions in the list of genes associated to this neuron. We use a hypergeometric test to check if a GO function is over-represented in a neuron. Given



He and Xie 2020

. CLEIT aims to represent the asymmetrical multi-level organization of the biological system by integrat- ing multiple incoherent omics data and to improve the prediction power of low-level features. CLEIT

CLEIT first learns the latent representation of the high-level domain then uses it as ground-truth embedding to improve the representation learning of the low-level domain in the form of contrastive loss

Besides, CLEIT can leverage the unlabeled hetero- geneous omics data to improve the generalizability of the predictive model.

several technical difficulties that hinder the application of existing machine learning methods. Firstly, omics data are often in an extremely high dimension. Secondly, the coherently labeled data are scarce com- pared with unlabeled data. Finally, it is not a trivial task to integrate heterogeneous omics data from different resources and modalities

Cross-
LEvel Information Transmission (CLEIT) network to address the aforementioned challenges. Inspired by domain adaptation techni- ques, CLEIT first learns to construct the low-dimensional latent representation that encodes signals indicative of tasks at hand from a high-level domain. Then, CLEIT uses the embedding from the high-level domain as ground-truth embedding to regularize the representation learning of the low-level domain in the form of a contrastive loss. In addition, we adopt a pre-training-fine-tuning ap- proach, where pre-training enables the usage of unlabeled heteroge- neous omics data to improve the generalizability of CLEIT, while fine-tuning is employed to enable more task-focused predictions given a specific labeled dataset

The machine learning models that can explicitly model hierarchical biological
processes will undoubtedly facilitate the development of personal- ized medicine. In

we aim to build accurate predictive models solely using mutation data as inputs to mimic the practical clinical setting, where only patient mutation profiles are available for drug screening.

we use a denoising Autoencoder as a building block and a pre-training-fine-tuning strategy to integrate noisy and sparse mutation, gene expression and protein-protein interaction data from different resources. Our

CLEIT aims to develop a framework that constructs an indicative knowledge-abundant low-dimensional latent space from a high di- mensional feature space of particular domains, which lacks salient discriminative information of tasks of interest.

We resort to a domain adaptation-inspired approach to combat such data limita- tion issues.

Domain adaptation aims to transfer the knowledge gained on
the source domain with sufficient labeled data to the target domain without or with limited labeled data when the source and target domains are of different data distributions. In

feature- based domain adaptation approaches (Weiss et al., 2016) have gained popularity along with the advancement in deep learning tech- niques due to their power in feature representation learning.

It aims to learn a shared feature representation by minimizing the discrep- ancy across different domains while leveraging supervised loss from labeled source domain samples to maintain trait space’s discrimina- tive power.

Although CLEIT borrowed some ideas from the domain adaptive transfer learning, there is a significant difference between CLEIT and those approaches. The

While in our case, we focus on resolving the inherent discriminative power dis- crepancy between two hierarchical related domains. The feature of the high-level domain has higher discriminative power than that of the low-level domain. Moreover,

Moreover, the entity types of source and tar- get domains are usually the same in conventional domain adapta- tion. In our case, they are of different types. Specifically,

Specifically, our goal for information transmission is to solely push the latent representa- tion of the low-level domain to approximate the one of the high- level domain; that is, the feature representation learned from the high-level domain is fixed and used as ground-truth feature repre- sentation of the low-level domain.

In this setting, the latent space where the CLEIT happens is no longer a symmetrical consensus from different domains. The high-level and low-level domain is used as an input and an output, respectively, to boost the discrimination power of the low-level domain. A mapping function is learned between them.

CLEIT only needs to use the mutation data as the input during the inference stage. During the training stage, the mutation and gene expression data can come from different data resources and be unlabelled. Thus, CLEIT is more practical than existing methods. Moreover, CLEIT explicitly models the hierarchical, asymmetrical information transmission in a biological system

a novel neural network framework that can explicit- ly model asymmetrical CLEITs in a complex system to boost the discriminative power of the low-level domain

The multi-level hierarchical structure is the fundamental characteristic of the biological and ecological system. The proposed architecture is general and can be applied to model various machine learning tasks where two domains have different features

The proposed neural network framework provides a new ap- proach to integrating multiple omics data vertically to represent the multi-level organization of a biological system.

We design a pre-training-fine-tuning strategy to fully utilize both labeled and unlabeled omics data that are naturally noisy, high-dimensional and sparse. In particular, the incorporation of autoencoder alleviated the high-dimensionality challenge of omics data and brought in denoising effects. Furthermore, the ef- fective usage of unlabeled data addressed the sparsity of labeled data.

CLEIT is the first deep learning-based framework designed to perform drug sensitivity prediction tasks solely on whole-genome somatic mutation profiles, which achieves comparable perform- ance to the model trained from gene expression profile

predict the phenotype of interest (e.g. cell viability following drug treatments) of a cell from its mutation profile. Due

Due to the multi-level hierarchical organization of a biological system, RNA-level gene expression profile, can achieve superior performance to DNA-level mutation data for pre- dicting phenotypes independent on machine learning models applied to them.

the performance difference is due to the nature of each data domain, instead of the volume of labeled samples as in a classical domain adaptation setting. However,

although feature spaces of DNA and RNA domains are not the same, the entities cross the feature spaces are hierarchically related, i.e.

this work aims to utilize the knowledge learned from the gene ex- pression data to boost the predictive power of the mutation profile.

we want to achieve the similar prediction perform- ance when only using the mutation data as features to that when using the gene expression data. Formally,

we propose a Cross-LEvel-Information Transmission (CLEIT) framework. The strategy of CLEIT is to encode the data from both domains into certain latent features. The embedded latent feature has the direct implication of the task of interests and achieves the CLEIT through transferring knowledge via learned representations cross domains

a novel machine learning framework CLEIT for the predictive modeling of genotype-phenotype associations by explicitly modeling the asymmetric CLEIT in the biological system

Although we only study the knowledge transfer between DNA level and RNA level in this article, the same strategy can be applied to other levels in the biological system, for example, imputing proteomics data using transcriptomics data.

the performance of CLEIT could be further improved by incorporating domain knowledge. For example, an autoencoder module that can model gene-gene interac- tions and biological pathways will

Another challenge in personalized medicine is to transfer knowledge from cell line data to patient tissue data (He and Xie, 2021). It



Cui et al. 2020 - IMAGE! !!

The proposed system consists of three major components. 1) The first component is an end-to-end cellular feature learning module using a deep neural network with global average pooling. The learned cellular representations encode high-level biologically relevant information without requiring individual cell segmentation, which is aggregated into patient-level feature vectors by using a locality-constrained linear coding (LLC)-based bag of words (BoW) encoding algorithm. 2) The second component is a Cox proportional hazards model with an elastic net penalty for robust feature selection and survival analysis. 3) The third commponent is a biomarker interpretation module that can help localize the image regions that contribute to the survival model’s decision.

ure maps as well as stride size equal to 1 and pad size of 1. The activa- tions of the GAP layer are used as feature representations of cells for the subsequent survival analysis

In addition, we probe into the neural network and local-
ize the discriminative image regions (attentions) for cell classification by following the method in [46]. Several examples of the training patches and the computed class activation maps (CAMs) are

the activa- tions of the GAP layer are robust with respect to image translations and are suitable for cell representations



Fu et al. 2020 - pas vraiment à voir not useful

we present a general convolutional neural network model that integrates multi-omics informa- tion to prioritize the candidate genes of objective traits

we present ISwine (http://iswine.iomics.pro/), which is an online comprehensive knowledgebase in which we incorporated almost all the published swine multi-omics data. Overall,

There are two commonly used strategies to integrate information from multiple omics. One is to narrow the large set of candidate genes by selecting the overlapping regions based on evidence from different layers of multiple omics, such as selecting the candidate genes that significantly affect the objective traits in both genomics and transcriptomics

The other strategy is to map credible candidates by constructing a network to interpret its functions and biological meanings, such as pathway analysis and co-expression network analysis, to locate the genes within the pathways that are associated with objective traits23,24. However, limited by sample size and experimental design, it is very rare to obtain the evidence from multiple omics information for a specific candidate gene in a single experiment.

we constructed a multi-
omics database for swine, which is an important non-model organism and one of the most important livestock animals. The

The lime framework (https://github.com/marcotcr/lime) was conducted further to understand the working principle of the CNN model, which suggested that “Nonsynonymous_indel”,
“Intron_snp”, “Expression”, “Module”, and “QTAL” played important roles in gene prioritization (Fig.

To further confirm the role of each omics in the gene prioritization model, we trained the LR, LinearSVC, MLP, and CNN models using the features of genomes, transcriptomes, and data from the literature. We

the performance of the model constructed using only genomic features was the best, followed by the model that used transcriptomes, and the model based on the literature was the worst. This



Choi and Quon 2021



we present a scalable, interpretable variational autoencoder (siVAE) that is interpretable by design: it learns feature embeddings that guide the interpretation of the cell embeddings in a manner analogous to factor loadings of factor analysis

We exploit a number of connections between dimensionality reduction and gene network inference to identify gene neighborhoods and gene hubs, without the explicit need for gene network inference. Finally,

we observe a systematic difference in the gene neighborhoods identified by dimensionality reduction methods and gene network inference algorithms in general, suggesting they provide complementary information about the underlying structure of the gene co-expression network

it is useful to “interpret” the embedding dimensions with respect to the input features. For example, in a visualization of a 2D cell embedding space based on scRNA- seq data, interpretation of the embedding dimensions would identify genes that may be responsible for variation in the transcriptome along different axes of the visualization (Fig.

). Our ability to interpret embedding dimensions rests directly on the dimensionality reduction technique used to compute them. DR approaches can be categorized based on whether they use a linear or non-linear reduction framework.

 Linear DR frameworks are considered less powerful because they can typically be viewed as a specific, restricted implementation of a non-linear framework12. The advantage of linear methods such as Principal Components Analysis (PCA) is that they provide a quantitative estimate of the contribution of individual features towards each embedding dimension. 

In contrast, while non-linear methods such as UMAP, t-SNE and variational autoencoders (VAEs) produce better visualizations in which cells of the same type cluster together more closely (Supplementary Fig. S1), they are not interpretable. That is, they do not estimate the contributions of features to individual embedding dimensions, and therefore require more ad hoc, downstream analysis to gain intuition about the arrangement of cells in the visualization (e.g. understand why specific cells cluster). Beyond

(siVAE) that combines the non- linear DR framework of variational autoencoders (VAEs) with the interpretability of linear PCA

VAEs are non-linear DR methods that uses neural networks to infer a cell embedding space. siVAE is a variant of VAEs that additionally infers a feature embedding space for the genomic features (genes or genomic regions) that is used to interpret the cell embedding space, while being comparable in training time and power to a standard VAE. Compared

the feature embeddings that siVAE learns are useful for characterizing aspects of gene regulatory networks (GRN) while avoiding the challenging process of gene network inference1

the feature embeddings can be used to identify communities of co- regulated genes.

siVAE can also find groups of co-regulated genes that are not readily identified by GRN methods, suggesting the two approaches to identifying co-regulated gene sets are complementary in their findings

siVAE identifies genes with high degree centrality more accurately than ranking genes by explicit node degree in a gene network,

Given that VAEs have been applied to a wide range of genomics data modalities (epigenomics16–18 and miRNA19) and analysis (visualization20,21, trajectory inference22, data imputation23, and perturbation response prediction24–26), our work can therefore enable interpretability in a wide range of downstream applications of VAEs

siVAE is a deep neural network consisting of two pairs of encoder-decoder structures, one for cells and the other for features (

. The cell-wise encoder-decoder learns to compress per-cell measurements Xci into a low dimensional embedding of length K for vizualization and analysis, similar to traditional VAEs 

To facilitate interpretation of the cell state space, siVAE additionally implements a separate feature-wise encoder-decoder network that learns to compress per-genomic features across the cells into a low dimensional embedding of length K analogous to the cell-wise encoder-decoder

The cell- and feature-wise decoders together are used to generate the observed measurement

The strategy siVAE uses to achieve interpretation is best understood by briefly reviewing why probabilistic PCA (PPCA) and factor analysis are interpretable

The underlying generative model behind PPCA can be thought of as similar to a VAE with a linear decoder, and the output of PPCA includes both a factor loading matrix and a score matrix

in PPCA the predicted expression of feature f is assumed to be the dot product of the loadings for feature f and the scores of cell c

PPCA is interpretable:  the larger the contribution of a feature f to a particular dimension k (indicated by the magnitude of v_fk), the more the measurement of feature f is influenced by a cell's corresponding score in that dimension; conversely when the magnitude of v_fk is small (or even 0), then the cell's corresponding score in that dimension does not influence the measurement of feature f in cell c => we say that the PPCA model enforces correspondence between the cell and feature embedding at dimension k

siVAE achieves interpretability of the siVAE scores z_c,k by adding a small interpretability regularization term to its objective function; this term penalizes the deviation between the observed measurement x_c,f and the dot product of the corresponding siVAE scores and the loadings; this small regularization term helps enforce some soft correspondence between dimension k of the cell scores and dimension k of the feature loadings 

siVAE interprets cell embedding spaces faster and more accurately than existing feature attribution approaches

Co-expressed genes cluster in the feature embedding space
Feature

Feature attributions, or factor loadings, of linear DR methods such as PCA have been exploited extensively in the literature to gain insight into the gene co-expression network (GCN); here

we explore the extent to which the siVAE loading matrix can be leveraged to gain insight into GCN structure. GCNs

GCNs are of interest because they can be used to identify (1) cell population-specific gene modules, representing groups of genes that are highly co-expressed and therefore are likely to function together in a cell type-specific manner, as well as (2) gene hubs, which are genes that are connected via an edge to many more genes than is typical in the network, and typically represent key functional genes in the cell

In our application of dimensionality reduction in which features are all centered and scaled uniformly, the goal of DR methods is to learn (linear or non-linear) patterns of co-expression amongst the input features, that allow accurate reconstruction of the input data from low dimensional representations. 

we view the siVAE loading matrix that siVAE infers as a non-linear analog of the PCA loading matrix. Indeed, one can view probabilistic PCA56 as a restricted form of a VAE in which all of the activation functions in the decoder are linear, no regularization is applied to the decoder weights, and the output distribution is an isotropic Gaussian



eigengenes (genes captured by factor loadings of PCA) represent network modules in the gene co-expression network5

We hypothesized that siVAE genes captured by feature loadings of siVAE may also represent network modules, and that co- expressed genes in the training data are also proximal in the siVAE feature embedding space.

We found that genes belonging to the same community co-localized in the feature embedding space, but interestingly, the hub nodes are embedded in distinct locations their corresponding community (Fig.

Our interpretation of this observation is that given the limited capacity of the cell embedding space, siVAE tends to keep information specifically about each hub because of their high degree centrality and uses each hub to reconstruct the remaining nodes of their corresponding community. On the other hand, non-hub genes within the same community co- localize in the feature embedding space because the limited capacity of the VAE forces non-hub genes to be predicted similarly, given the retained information about the hub. Interestingly,

the KL divergence term of the feature-wise encoder-decoder of siVAE will tend to draw genes towards the origin

because isolated genes by definition do not co-vary with other genes, information about their expression pattern will tend to be lost during compression, leading the VAE to tend to predict the average expression level of that gene in the decoder (which will be 0, because of data centering). This in turn encourages the feature embedding to be at the origin because the interpretability term encourages the linear product of the feature embedding with the feature loadings to predict the gene’s expression pattern, so if a feature is located at the origin in the feature embedding space, it will cause the predicted expression to be 0.

co-expressed genes cluster in the feature embedding space

markers of the same cell type tend to cluster in feature embedding space as expected (Fig. 4d). Our results overall suggest that co-expressed genes tend to co-localize in siVAE feature embedding space.

Our observation that hub genes in a community are treated differently by siVAE led us to hypothesize that we may be able to identify hub genes from a trained siVAE model without inferring a GRN.

We reasoned that because hub genes are connected to so many other genes, siVAE is more likely to store the expression patterns of hub genes in the compressed representation (latent embedding) for use in reconstructing the rest of the gene expression patterns.

We therefore hypothesized that we could identify hub genes as those genes that are well reconstructed by a trained siVAE model, because if siVAE captures variation in hub gene expression in the cell embedding space, it should also reconstruct the hub gene expression more accurately than other genes

**We therefore used gene-specific reconstruction accuracy in the siVAE model as GRN-free measure of degree centrality**

siVAE consistently selects genes with the largest cumulative degree centrality of all tested methods

these results in total suggest that using siVAE, we can identify high degree centrality genes more accurately than the more classic approach of first inferring a gene co-expression network before identifying high degree centrality genes

we explored the extent to which we could identify neighboring genes that share an edge in a GRN, without having to infer GRNs explicitly. Gene neighbors tend to share similar function62, interact with one another63 and/or belong to the same gene community64. Identification of gene neighbors therefore aids in identifying co-functional genes in the cel

we hypothesized that we could identify gene neighbors directly using a trained siVAE model, instead of having to first infer an explicit GRN. 

GRN inference methods typically output edge weights between pairs of nodes in the network, where larger weights correspond to a greater chance the two nodes share an edge in the underlying GRN. For

For siVAE, we generate edge weights in two ways: (1)

(1) siVAE-Euc, the Euclidean distance of the two genes in the feature embedding space, where smaller distances correspond to closer proximity, and

(2) siVAE-GRN, where we first sample a new scRNA-seq dataset from siVAE that matches the size of the training data, then run a GRN inference method (ARACNE, MRNET, CLR, and GRNBOOST2) on the sampled scRNA-seq dataset to calculate edge weights between genes.

When considering the overlap in neighbors selected by different methods, it is striking how the dimensionality reduction methods cluster strongly (scVI, siVAE, LDVAE) and the GRN inference- based methods cluster strongly as well, with markedly less overlap between these two groups

This is surprising in part because the neighborhood sets are all approximately of the same predictive performance (Fig. 5c), suggesting the DR methods are systematically identifying different neighbors that are as equally co-expressed as the set identified by the GRN methods. In

siVAE-GRN involves identifying gene neighbors using the GRN inference methodology, but just applied to a siVAE-generated dataset (instead of the original training dataset). 

under the siVAE-GRN neighborhood identification framework, the neighborhood genes are still much more similar to siVAE than to the GRN inference methods, suggesting the unique neighborhood identified by the DR methods is a property of the co- expression patterns that DR methods learn, and not due to the way in which neighborhood genes are identified.

Our results therefore suggest that since GRN- and dimensionality reduction-identified neighbor sets are systematically different but approximately equally predictive of neighboring genes, then both approaches should be used to find co-expressed genes in a network

In addition to showing how co-expressed groups of genes can be identified, we also showed how we can identify hub genes, without inferring an explicit GCN. This is useful because GCN inference continues to be a highly challenging task, even in the era of large numbers of cells sequenced from single cell assays15. B

By comparing VAEs trained on different cell populations, it is likely possible to identify differential co-expression patterns between cell populations, also without explicit GCN inference.

the set of neighbors of a given gene with respect to the underlying GCN is systematically different between explicit GCN inference methods and the dimensionality reduction methods. This

**One possible explanation is that DR methods can learn to combine many genes into a single embedding dimension, whereas explicit GCN inference methods ultimately represent co-expression patterns as individual edges between only pairs of genes, and therefore are more limited in their capacity to represent higher order co-expression patterns.**

RE-VAE16, methCancer-gen17, VAEMDA19, scMVAE18, scVI21, Dr.VAE25, scGen26, and Dhaka22 could also so benefit from similar interpretability terms such as that used for siVAE

methods such as InfoGAN72, FactorVAE48, DirVAE73 and others70,74,75 modify generative models such as the VAE to achieve disentangled representation by encouraging the individual cell dimensions to be statistically independent

we do not consider these model variants here because they do not provide contributions of individual features to cell dimensions. These approaches still require users to manually draw samples of points from the cell embedding space, reconstruct the input features from the cell dimensions, then use human intervention to manually inspect how variation across specific dimensions might correspond to human-interpretable factors of variation. However,

the regularization terms that encourages disentanglement between the cell dimensions may be applied to siVAE.

This would help remove the entanglement between cell dimensions such as the overlapping outlines of digits in siVAE loadings for the MNIST dataset

The key idea behind siVAE is that we jointly infer cell-wise and feature-wise state spaces, and through regularization, loosely enforce correspondence between the cell and feature dimensions.

correspondence means variation in dimension k in the cell embedding space corresponds to observed variation in each feature f that is proprotional to feature f's embedding coordinate in dimension k

through correspondence, the feature embedding coordinates (siVAE loadings) become analogous to factor loadings

the cell embedding coordinates (sivAE scores) become analogous to the factor scores of PCA

the feature and cell embeddings are sampled from different latent spaces and projected to higher dimensions through separate decoders, before combining to produce the means of the Gaussians

siVAE turns the last layer of weights leading to the Gaussian mean of the VAE into a non-linear transformation of the latent variables

siVAE can therefore be viewed as putting a prior over a single (last) layer of weights in the VAE

the matrix V encodes the siVAE loadings while the matrix Z encodes the siVAE scores

we can compute siVAE loadings and scores of other hidden layer as well (but here focused on latent space l=1)

the input for 2 encoders is different

1. a vector of observations for a single feature across all training cells
2. a vector of observations for a single cell across all features

the size of input for feature-wise encoder-decoder increases with the number of cells, which can be very high (millions of input nodes)

downsample the input through i) downsampling or ii) PCA

w training the feature-wise encoder-decoder with downsampled and PCA inputs both results in loss and clustering accuracy score comparable to that of model trained with the full data.

identical neural net designs were used across the feature-wise and cell-wise encoders and decoders in siVAE. The

siVAE is implemented as a Python package and is available from PyPi (https://pypi.org/project/siVAE

Two separate Python packages were used to compute neural network feature attributions in our experiments. We used the DeepExplain Python package that implemented all feature attribution methods (Saliency Maps, Grad*Int, DeepLIFT, IntGrad, Shapley Value) included in our experiments in reverse-mode77. We used the tensorflow-forward- ad Python package for computing Saliency Maps and Grad*Int in forward-mode78

Gene Relevance, we used the published R package45. The method required the latent embeddings learned from siVAE as well as the raw count data corresponding to the embeddings.



Gene Relevance and other methods output a vector of contributions of feature f to all cell dimension d for cell c

in contrast, siVAE loadings represent a vector of contribution of feature f to all cell dimensions, summarized over all cells

Estimating gene centrality using siVAE. We reasoned that the expression patterns of genes with high degree centrality would be most likely to be retained by siVAE during dimensionality reduction, because those genes could be used to reconstruct the expression patterns of the many other genes connected to them. If so, then the hub genes would also be likely to be the genes whose expression patterns are reconstructed with the lowest error. We therefore define gene centrality for siVAE as the negative reconstruction error of siVAE on each individual gene during training.

Estimating gene centrality using GCN inference methods. The GCN inference methods tested here all output pairwise weights between genes, where larger weights indicated higher confidence in a pairwise edge in the underlying GCN. We therefore measured each query gene’s degree centrality for GCN inference methods by averaging the weights between the query gene and every other gene in the network

we used siVAE to also identify the closest co-expression neighbors of every gene in the genome, using two different approaches based on leveraging the feature embedding space. 

1. 'distance-based network neighbors': we used the  Euclidean distance in the feature embedding space as a measure of distance between 2 genes in the network; the k nearest neighbors of a given query gene were defined as the k genes with shortest distance to the query gene
2. 'GCN-based approach': passing a matrix of feature embeddings to a GCN inference method as input in place of a typical gene expression matrix input, in order to infer a classic gene co-expression network; from this gene expression network we extracted the nearest neighbors of every gene according to the strategy described for GCN inference methods

Identifying gene co-expression network neighbors using GCN inference methods. For GCN inference methods, we used the output adjacency matrix to identify the closest 20 neighborhood genes per target gene based on largest pairwise weights for each gene



Kinalis et al. 2019

With specialized training, the autoencoder is not only able to generalize over the data, but also to tease apart biologically meaningful modules, which we found encoded in the representation layer of the network

Our model can, from scRNA-seq data, delineate biological meaningful modules that govern a dataset, as well as give information as to which modules are active in each single cell. Importantly,

most of these modules can be explained by known biological functions, as provided by the Hallmark gene sets

tailored training of an autoencoder makes it possible to deconvolute biological modules inherent in the data, without any assumptions

By comparisons with gene signatures of canonical pathways we see that the modules are directly interpretable.

we applied autoencoder neural networks
[16], unsupervised machine learning methods, to scRNA-seq expression counts

are able to ef- ficiently capture the underlying signal even when the in- put is perturbed or zeroed out [17], which is particularly appealing for an application to scRNA-seq data

apply methods from the computer graphics com- munity, known as saliency maps [27], aiming to deconvolute what the latent representation of the model captures, and to interpret it in terms of biological pathways

In this study we trained an autoencoder with a soft or-
thogonality constraint on the representation layer along- side a Poisson loss function. The orthogonality constraint pushes the representation layer to contain information that is disentangled between units.

. With a suitable learning rate we were able to train the model directly on the read count data (without log normalization or preprocessing)

. Our aim is to deconvolute the resulting model and establish a link be- tween the representation layer of our model and biological function

We evaluate the impact of gene sets on the rep- resentation layer of the network by the use of saliency maps. Strikingly, we find that each hidden unit in the dis- tributed model appears to model a distinct term or modal- ity in the data

We saw less entanglement or spillover between nodes, than we expected given the colinearity of gene expression data. It appears that the division of labour is well-defined, and may have intelligible interpretation

Heatmaps of the impact of the Hallmark molecular pathways on the representation layer of the autoencoder trained on Paul et al. The impact is computed via saliency maps

We added the soft or- thogonality criterion in the loss function, as an attempt to deconvolute the highly correlated biological signal, and so that each of the hidden units correspond in essence to one dimension of the representation layer. The

Although the aforementioned methods exhibit better clustering performance than our model, partly due to the application of graph-based methods, the marker gene detec- tion in both methods relies upon identification of differen- tially expressed genes, via simple statistical tests of multiple regression. These tests may be suitable for identification of marker genes of simple traits, but for more complex data- sets with added heterogeneity like cancer, this approach may prove insufficient. A nonlinear neural network is suitable for pattern recognition in complex data and through guided backpropagation of the signal (as performed with saliency maps), we can identify the most important input features (genes) that affect the formation of those patterns. This

We trained an autoencoder with 2 layers for encoding and 2 for decoding, with dimensions 128, 64 and 128 for the hidden layers. The size of the representation layer was chosen to slightly exceed the number of gene sets under investigation, in our case the hallmark molecular path- ways. We

We limited the input dataset to the genes that were present in the signatures, for faster training and memory fit. The

The model was trained with a Poisson negative log-likelihood loss function, to ac- count for the fact that RNA-sequencing expression levels are count data.

The idea behind vanilla saliency maps in deep learning
is rather intuitive. We compute the gradient of the repre- sentation units with respect to the gene expression input, by testing each representation unit in isolation. That is, we consider that only one representation unit has positive gradient equal to one and the rest have gradient 0, and we let the gradient backpropagate through the network. This way we can see how the representation is affected by small changes in the gene expression levels, or in other words, the impact that each gene has on each representation unit

the guided backpropagation sali- ency maps, that has shown more clear results [48]. The difference is that only positive gradients flow back to the network, the negative gradients are clipped

In order to compute the impact of a gene set to each hid-
den unit, we simply take the arithmetic mean of the impact of the genes in the set. The resulting pathway impact scores are min-max scaled to the range [0, 1]. In the com- parison scenario, the impact scores of the cells to compare are subtracted and then scaled. The scaling is now per- formed by division with the maximum value of the differ- ence in impact scores, so the final pathways impact scores fall in the range [− 1, 1]. Hidden



Svensson et al. 2020



PCA models data as aris- ing from a continuous multivariate Gaussian distribution, and thus optimizes a Gaussian likelihood (Pearson, 1901; Tipping and Bishop, 1999). This model assumption is at odds with the count data meas- ured in single-cell RNA-seq (Svensson, 2020; William Townes et al., 2019), and leads to interpretation problems (Hicks

by adapting the method of scVI (Lopez et al., 2018), we demonstrate a scalable approach to learning a latent representation of single-cell RNA-seq data, that identifies the relationship between cell represen- tation coordinates and gene weights via a factor model.

whereas typically autoencoder models are designed with the same network topology in the inference func- tions and the reconstruction functions, what we propose is a restricted reconstruction function that leads to an increase in recon- struction error. However, by virtue of being linear, our reconstruc- tion function provides an interpretable link between gene programs and cellular molecular phenotypes

We replace the neural network fW znðÞ with a linear function:

This way the expression level lg
n of a gene g in a cell n is affected
by the weights wd g depending on the coordinate zd
n of a cell n, giving
a direct link between cell representation and gene expression.

a linearly decoded variational autoencoder (LDVAE) in scVI

With either VAE or LDVAE, the representation Z can be used to learn which cells are similar to each other and can be used for clustering.

the axes of representation learned by the LDVAE model can be directly related to axes of co-expressed genes

The learned Z representations from the different models can be compared by investigating the covariance matrix ^Z
T ^Z (where ^Z is a
centered and scaled version of Z). This illustrates that LDVAE learns representations with fewer covarying factors zd

Unlike linear methods, the VAE is not constrained by covarying factors since the non-linear neural network fW ?ðÞ can produce vastly different gene expressions along a linear path in the Z representa- tion. Comparing

Comparing the proposed alternative LDVAE models, using a normal latent distribution induces less correlation between factors.

By performing eigen decomposition on a covariance matrix the pro- portion of variance explained by each factor can be quantified. This allows ordering of factors which can be used to identify the regula- tory programs with the most variation across the dataset. It also illustrates the simplicial structure of ln distributed latent variables since one factor is always linearly dependent on the other factors



Liu et al. 2021

. TranSynergy is designed so that the cellular effect of drug actions can be explicitly modeled through cell-line gene dependency, gene-gene interaction, and genome-wide drug-target interaction. A novel Shapley Additive Gene Set Enrichment Analysis (SA- GSEA) method has been developed to deconvolute genes that contribute to the synergistic drug combination and improve model interpretability

Novel pathways that are associated with the synergis- tic combinations are revealed and supported by experimental evidences.

We have developed a knowledge-enabled deep learning model, TranS- ynergy, to predict synergistic drug combinations

A novel Shapley Additive Gene Set Enrich- ment Analysis (SA-GSEA) method is introduced to improve the interpretability ofthe machine learning model. Using TransSynergy and SA-GSEA, we can deconvolute genes responsible for the synergistic drug combination, suggesting the potential ofmachine learning in developing precision anti-cancer therapy

a mechanism-driven and self-attention boosted deep learning model TranSynergy for the prediction ofsynergistic drug combinations and the deconvolution ofcellular mechanisms contributing to them

We applied the random walk with restart algorithm (RWR) on a protein-protein interaction (PPI) network to infer a novel drug-target profile as the drug features

For the features ofeach cell line, we used gene expres- sions or gene dependencies profile. These mechanism related features make the model readily interpretable

we applied the self-attention transformer to encode the gene-gene interactions responsible for the synergistic drug combination.

To reveal novel genes that are associated with the synergistic drug combination from the learned biological relations in the TranSynergy model, we developed a novel Shapley Additive Gene Set Enrichment Analysis (SA-GSEA) based on SHAP [33]. The revealed novel gene set may serve as a patient-specific biomarker for precision medicine or drug targets for discovering new cancer combination therapy. 

TranSynergy is a transformer boosted deep learning model for the prediction ofdrug combi- nation synergy. It includes three major components, input dimension reduction component, self-attention transformer component, and output fully connected component (Fig

input features are composed ofthree vectors

The first two columns are the representations oftwo drugs. The third column is the representation ofthe cell lines.

. In the matrix, each row corresponds to a gene or protein, and encodes the impact ofdrug on the gene

The input dimension reduction component is a single-layer neural network to reduce the dimension of input. The

The modified transformer component takes the output from the first component and includes a scaled dot product based self-attention mechanism module

Here, the self-attention is applied to model gene-gene interactions. It is also worth noting that we customized the transformer model by removing the positional encoding layer since the order input feature dimensions should be irrelevant to the final prediction.

Then the final output ofthe predicted synergy score comes from a fully connected neural network. The

The input ofour deep learning model includes the vector representations oftwo drug mole-
cules in the drug combination and a cell line that is treated by the drug combination. O

We also need to encode the effect ofdrugs on down-stream non-target proteins and the whole biological sys- tem. The protein-protein interaction network is utilized to infer the drug response ofthe non- target proteins considering that the protein-protein interaction mediates information trans- mission in the biological system

We apply the RWR algorithm to simulate this network propa- gation process

Compared with the chemical information-based approaches for drug representation, the target-based representation ofdrug molecules has the following advan- tages. Firstly, drug target information is closely related to the cellular response to the drug treatment at both the molecular level and system level. Secondly, it makes it possible to explain the model output, drug combination synergy, in terms ofthe contribution ofeach protein or gene

Because drug-combination therapy has cell line-specific responses, another important com-
ponent ofinputs is the cell line vector representation. The DeepSynergy uses gene expression profile as the cell line vector representation [24]. We have applied a novel alternative strategy to infer cell line vector representation. The

The gene essentiality varies in the different cell lines and plays a critical role in anti-cancer drug sensitivity. Intuitively, drugs that affect essential proteins will cause the cell to have a more devastating response. Thus,

Thus, we take gene essentiality or gene dependence into account and this information is one ofthe inputs into our mode

To investigate whether the gene-gene interaction network propagation step is essential for the model performance, we compared the TranSynergy model trained with only observed drug target information with that trained with network propagated drug target information

we implemented two novel infrastructures, TranSynergyCI and TranSyner-
gyGNF, to investigate whether the prediction could be improved further by integrating extra chemical information.

s adding extra chemical information may not be necessary to boost the perfor- mance any further in this experimental setup.

Shapley Additive Gene Set Enrichment Analysis (SA-GSEA) to deter- mine the oncogenic signature and the underlying mechanisms associated with each synergistic drug combination (see

Because each ofthe features in TranSynergy corresponds to a gene, the Shapley value essentially indicates the attri- bute ofeach gene to the synergy prediction. Moreover, genes could be ranked based on the Shapley value ofeach input gene feature. This makes it feasible to perform GSEA analysis.

a novel deep learning model TranSynergy for the synergy score prediction and mechanism deconvolution ofdrug combination cancer therapy

the network propagated drug target profile, which indicated both drug-tar- get interaction and drug effect on non-targeted proteins, was crucial for the comprehensive representation ofdrug features.

gene essentiality in the cancer cells is a more desirable cell line representation than raw gene expression profile.

, many explainable AI methods have been pro- posed, such as input perturbation methods [60,61], backpropagation based methods [62], and the calculation ofSHAP values [33].

Attention-based approaches have been proposed to inter- pret the models using attention mechanisms.

attention weights learned from self-attentions may not provide a meaningful explanation for the final prediction

we carefully design the input features so that each feature dimension is corresponding to a gene and is easily interpretable. Through examining the SHAP values ofgene-wise input feature, we extract the information regarding the effect of drug-target interactions and gene-gene interactions on the cancer cell response.

The transformer has been widely used and shown promising performance
in many different applications, including natural language processing and image processing [29–31]. It includes two major components, encoder and decoder. The input for both encoder and decoder has three matrices, query, key and values. Both encoder and decoder contain many sublayers. Each sublayer is comprised ofthree stages, attention mechanism, add & norm stage, and feed forward stage. The add & norm stage contains a residual structure and a layer normalization structure. The attention mechanism is the module to encode the interaction of different features with the following equation: